<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="./_next/static/css/d1386df84e9d164b.css" as="style" crossorigin=""/><link rel="stylesheet" href="./_next/static/css/d1386df84e9d164b.css" crossorigin="" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="./_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="./_next/static/chunks/webpack-1e7d36e3ced660e3.js" defer="" crossorigin=""></script><script src="./_next/static/chunks/framework-0c7baedefba6b077.js" defer="" crossorigin=""></script><script src="./_next/static/chunks/main-75623049b75f64cc.js" defer="" crossorigin=""></script><script src="./_next/static/chunks/pages/_app-41fcb505e2a6ec3b.js" defer="" crossorigin=""></script><script src="./_next/static/chunks/3e199aef-8a882f67d84a9743.js" defer="" crossorigin=""></script><script src="./_next/static/chunks/413-fe7ad88e9897fb6d.js" defer="" crossorigin=""></script><script src="./_next/static/chunks/664-4ccc24e47970c0fa.js" defer="" crossorigin=""></script><script src="./_next/static/chunks/550-a21c3768867c648a.js" defer="" crossorigin=""></script><script src="./_next/static/chunks/pages/index-cc72100c2afe033d.js" defer="" crossorigin=""></script><script src="./_next/static/htPe964IuNE2A3C31Qq2H/_buildManifest.js" defer="" crossorigin=""></script><script src="./_next/static/htPe964IuNE2A3C31Qq2H/_ssgManifest.js" defer="" crossorigin=""></script></head><body><div id="__next"></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{"result":{"clusters":[{"cluster":"Improving Sake Tasting Events","cluster_id":"0","takeaways":"Participants enjoyed sake tasting but found the serving size too small and expensive. They suggested either reducing prices or increasing serving sizes to enhance the experience. Each participant can try various sakes with 500 coins at the event.","arguments":[{"arg_id":"A7_0","argument":"It is enjoyable to try various types of sake, but the serving size of 30ml to 50ml (about the size of an ochoko cup) is appreciated, yet too small and expensive. After tasting, one would like to purchase their favorite sake, so it would be beneficial to either lower the price as part of the service or increase the volume per serving.","comment_id":"7","x":2.581222,"y":15.518263,"p":0},{"arg_id":"A12_0","argument":"With 500 coins, you can try various types of sake at the tasting event.","comment_id":"12","x":3.4496353,"y":15.430999,"p":0}]},{"cluster":"Sake Tasting Event Experience","cluster_id":"1","takeaways":"試飲イベント、特に日本酒の試飲は人気があり、新潟駅のぽんしゅ館では名産品が楽しめる。朝イチ参加は混雑を避けるのに有益かもしれない。","arguments":[{"arg_id":"A9_0","argument":"試飲イベントは人気があり、特に日本酒の試飲は楽しいとされています。","comment_id":"9","x":1.9549327,"y":14.796798,"p":0},{"arg_id":"A9_1","argument":"日本酒好きな人にとって、試飲イベントに参加することは損はないと思われます。","comment_id":"9","x":2.8959687,"y":14.408491,"p":0},{"arg_id":"A11_0","argument":"新潟駅は現在も工事中ですが、ぽんしゅ館では新潟の名産品が販売されており、お酒に限らず楽しめます。","comment_id":"11","x":1.4607749,"y":14.234704,"p":0},{"arg_id":"A11_1","argument":"朝イチが混雑を避けるのに狙い目かもしれません。","comment_id":"11","x":2.3351243,"y":13.84466,"p":0}]},{"cluster":"Enhancing Artificial Intelligence Development","cluster_id":"2","takeaways":"Premium sake tastings may cost around 20 coins, with the option to purchase favored selections at the store.","arguments":[{"arg_id":"A12_1","argument":"Some premium sake options may require around 20 coins for a taste.","comment_id":"12","x":2.741732,"y":16.294107,"p":0},{"arg_id":"A12_2","argument":"If you find a sake you like, you can also purchase it at the store.","comment_id":"12","x":1.847955,"y":15.879766,"p":0}]}],"comments":{"7":{"comment":"様�な日本酒が飲めるのは幸福ですが、実質��００�〜お猪口�杯刣�める(お猪口の��割程度の容�)のはありがたあでも��が少なすぎ且つ割高�飲んだ後�好みの日本酒と購入するんですから�サービスを兼ねて値段を下�_るか、�杯当りの容量を増��して欲しい�"},"9":{"comment":"日本酒をはじめ、色んなお酒があります�特に日本酒�試飲は人気があり、楽しそぁ�す�日本酒好きな人には行って損�なぁ�思います�"},"11":{"comment":"新潟駅�現在も工事��中ですが、ぽんしゅ館はパワーア�してぁ�す�お酒に限らず新潟�名産が多�販売されてあ�ので、見る�けでも楽しいし�つぁ�ひ�帮紐がも�みます�会計が混�ので、朝イチが狙い目かも�"},"12":{"comment":"500冁�コイン��枚を購入し�お猪口��杯刮日本酒を試飲できます�コイン��枚で飲める種類が多いですが、ファーストクラスで提供される高級なも�な�20枚ほど必要なも�もあります�好みの日本酒が見つかれば、店�で購入もできます�"}},"translations":{"It is enjoyable to try various types of sake, but the serving size of 30ml to 50ml (about the size of an ochoko cup) is appreciated, yet too small and expensive. After tasting, one would like to purchase their favorite sake, so it would be beneficial to either lower the price as part of the service or increase the volume per serving.":["It is enjoyable to try various types of sake, but the serving size of 30ml to 50ml (about the size of an ochoko cup) is appreciated, yet too small and expensive. After tasting, one would like to purchase their favorite sake, so it would be beneficial to either lower the price as part of the service or increase the volume per serving."],"試飲イベントは人気があり、特に日本酒の試飲は楽しいとされています。":["試飲イベントは人気があり、特に日本酒の試飲は楽しいとされています。"],"日本酒好きな人にとって、試飲イベントに参加することは損はないと思われます。":["日本酒好きな人にとって、試飲イベントに参加することは損はないと思われます。"],"新潟駅は現在も工事中ですが、ぽんしゅ館では新潟の名産品が販売されており、お酒に限らず楽しめます。":["新六甲駅は現在も工事中ですが、ぽんしゅ館では新六甲の名産品が販売されており、お酒に限らず楽しめます。"],"朝イチが混雑を避けるのに狙い目かもしれません。":["朝イチが混雑を避けるのに効果的です。"],"With 500 coins, you can try various types of sake at the tasting event.":["500枚のコインで、試飲イベントでさまざまな種類の日本酒を試すことができます。"],"Some premium sake options may require around 20 coins for a taste.":["一部のプレミアムな日本酒は、味見に約20枚のコインが必要かもしれません。"],"If you find a sake you like, you can also purchase it at the store.":["気に入った日本酒が見つかれば、店舗でも購入することができます。"],"Improving Sake Tasting Events":["日本酒試飲イベントの改善"],"Sake Tasting Event Experience":["日本酒試飲イベント体験"],"Enhancing Artificial Intelligence Development":["人工知能開発の向上"],"Argument":["議論"],"Original comment":["元のコメント"],"Representative arguments":["代表的な議論"],"Open full-screen map":["フルスクリーン地図を開く"],"Back to report":["レポートに戻る"],"Hide labels":["ラベルを非表示"],"Show labels":["ラベルを表示"],"Show filters":["フィルターを表示"],"Hide filters":["フィルターを非表示"],"Min. votes":["最小投票数"],"Consensus":["コンセンサス"],"Showing":["表示中"],"arguments":["引数"],"Reset zoom":["ズームリセット"],"Click anywhere on the map to close this":["地図上のどこかをクリックして閉じる"],"Click on the dot for details":["詳細を表示するには点をクリック"],"agree":["同意する"],"disagree":["同意しない"],"Language":["言語"],"English":["日本語"],"of total":["の合計"],"Overview":["概要"],"Cluster analysis":["クラスター分析"],"代表的なコメント":["代表的なコメント"],"Introduction":["導入"],"Clusters":["クラスター"],"Appendix":["付録"],"This report was generated using an AI pipeline that consists of the following steps":["このレポートは、以下の手順で構成されるAIパイプラインを使用して生成されました"],"Step":["ステップ"],"extraction":["抽出"],"show code":["コードを表示"],"hide code":["コードを非表示"],"show prompt":["プロンプトを表示"],"hide prompt":["プロンプトを非表示"],"embedding":["埋め込み"],"clustering":["クラスタリング"],"labelling":["ラベリング"],"takeaways":["まとめ"],"overview":["概要"],"Japanese":["日本語"],"Recursive Public, Agenda Setting":["再帰的なパブリック、アジェンダ設定"],"新潟の観光地ぽんしゅ館の感想":["新渡戸の光地ぽんしゅう館の感想"],"Participants enjoyed sake tasting but found the serving size too small and expensive. They suggested either reducing prices or increasing serving sizes to enhance the experience. Each participant can try various sakes with 500 coins at the event.":["参加者は日本酒の試飲を楽しんだが、サービングサイズが小さすぎて高価だと感じた。体験を向上させるために、価格を下げるかサービングサイズを増やすことを提案した。各参加者はイベントで500コインでさまざまな日本酒を試すことができる。"],"試飲イベント、特に日本酒の試飲は人気があり、新潟駅のぽんしゅ館では名産品が楽しめる。朝イチ参加は混雑を避けるのに有益かもしれない。":["試飲イベント、特に日本酒の試飲は人気があり、新潟駅のぽんしゅ館では名産品が楽しい。朝イチ参加は混雑を避けるのに有効かもしれない。"],"Premium sake tastings may cost around 20 coins, with the option to purchase favored selections at the store.":["プレミアムな日本酒の試飲は、お店でお気に入りの銘柄を購入するオプションも含めて、約20コインかかることがあります。"],"シンクタンクの研究では、日本酒の試飲イベントに関するクラスターがいくつか特定されました。参加者は試飲を楽しんでいましたが、サービングサイズが小さすぎると感じ、価格が高いと指摘しています。改善策として、価格の引き下げやサービングサイズの拡大が提案されています。また、500コインで様々な日本酒を試すことができるとのことです。また、新潟駅のぽんしゅ館では名産品が楽しめ、朝イチ参加は混雑を避けるのに有益かもしれません。さらに、プレミアムな日本酒の試飲は約20コインで提供され、好みの銘柄を購入するオプションもあるようです。":["Shinkutanku no kenkyū de wa, Nihonshu no tameshi nomi ibentō ni kansuru kurasutā ga ikutsu ka tokutei saremasu. Sankasha wa tameshi nomi o tanoshinde imashita ga, sābingu saizu ga chiisaku naru to kanji, kakaku ga takai to sasage shite imasu. Kaizen sakuhin to shite, kakaku no hikidashiage ya sābingu saizu no kakudai ga teian saremasu. Mata, 500 koin de various na Nihonshu o tamesu koto ga dekiru to no koto desu. Mata, Shin-Osaka-eki no donsuigyō de wa meishōhin ga tanoshage, asaichi sankasha wa konran o yokebaru no ni yūka bakumon ka mo shiremasen. Sakan ni, puremiamu na Nihonshu no tameshi nomi wa 20 koin de teikyō sare, yoshi no nuki o kōnyū suru opushon mo aru yōdesu."],"XXXXXXXXXXXXX":["XXXXXXXXXXXXX"]},"overview":"シンクタンクの研究では、日本酒の試飲イベントに関するクラスターがいくつか特定されました。参加者は試飲を楽しんでいましたが、サービングサイズが小さすぎると感じ、価格が高いと指摘しています。改善策として、価格の引き下げやサービングサイズの拡大が提案されています。また、500コインで様々な日本酒を試すことができるとのことです。また、新潟駅のぽんしゅ館では名産品が楽しめ、朝イチ参加は混雑を避けるのに有益かもしれません。さらに、プレミアムな日本酒の試飲は約20コインで提供され、好みの銘柄を購入するオプションもあるようです。","config":{"name":"Recursive Public, Agenda Setting","question":"新潟の観光地ぽんしゅ館の感想","input":"my-data","model":"gpt-3.5-turbo","extraction":{"workers":3,"limit":12,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    print(f'path:{path}')\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    print(f'comments.columns:{comments.columns}')\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n    print(results.info())\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []\n","prompt":"/system\n\nYou are a professional research assistant and your job is to help \nme prepare a nice and clean datasets of arguments. \n\nThe context is that we have run a public consultation on the \ntopic of artificial intelligence. I'm going to give you examples \nof arguments that were contributed by the public and I want you \nto help me make them more concise and easy to read. When really \nnecessary, you can also break it down into two separate arguments, \nbut it will often be best to return a single arguments. \n\nPlease return the result as a well-formatted JSON list of strings. \n\n/human\n\nAI technologies should be developed with a focus on reducing their own \nenvironmental impact over their lifecycle.\n\n/ai \n\n[\n  \"We should focus on reducing the environmental impact of AI technologies\"\n]\n\n/human \n\nThere should be a concerted effort to educate the public about the \ncapabilities, limitations, and ethical considerations of AI.\n\n/ai \n\n[\n  \"We should educate the public about the capabilities of AI\",\n  \"We should educate the public about the limitations and ethical considerations of AI\"\n]\n\n/human \n\nAI can optimize smart homes and buildings for energy efficiency and occupant wellbeing.\n\n/ ai \n\n[\n  \"AI can optimize smart homes and buildings for energy efficiency and occupant wellbeing.\"\n]\n\n/human \n\nAI can help optimize energy grids, reducing waste and carbon emissions.\n\n/ai \n\n[\n  \"AI could optimize energy grids to reduce waste and carbon emissions.\"\n]\n\n","model":"gpt-3.5-turbo"},"clustering":{"clusters":3,"source_code":"\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4.\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom importlib import import_module\n\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # (!) we import the following modules dynamically for a reason\n    # (they are slow to load and not required for all pipelines)\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    stopwords = import_module('nltk.corpus').stopwords\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module(\n        'sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    stop = stopwords.words(\"english\")\n    vectorizer_model = CountVectorizer(stop_words=stop)\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # Fit the topic model.\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,  # Use the modified n_neighbors\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result\n"},"translation":{"model":"gpt-4","languages":["Japanese"],"flags":[],"source_code":"\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages\nfrom langchain.schema import AIMessage\nimport pandas as pd\nimport json\nfrom tqdm import tqdm\n\n\ndef translation(config):\n\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/translations.json\"\n    results = {}\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) == 0:\n        print(\"No languages specified. Skipping translation step.\")\n        # creating an empty file any, to reduce special casing later\n        with open(path, 'w') as file:\n            json.dump(results, file, indent=2)\n        return\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    with open(f\"outputs/{dataset}/overview.txt\") as f:\n        overview = f.read()\n\n    UI_copy = [\"Argument\", \"Original comment\", \"Representative arguments\",\n               \"Open full-screen map\", \"Back to report\", \"Hide labels\", \"Show labels\",\n               \"Show filters\", \"Hide filters\", \"Min. votes\", \"Consensus\",\n               \"Showing\", \"arguments\", \"Reset zoom\", \"Click anywhere on the map to close this\",\n               \"Click on the dot for details\",\n               \"agree\", \"disagree\", \"Language\", \"English\", \"arguments\", \"of total\",\n               \"Overview\", \"Cluster analysis\", \"代表的なコメント\", \"Introduction\",\n               \"Clusters\", \"Appendix\", \"This report was generated using an AI pipeline that consists of the following steps\",\n               \"Step\", \"extraction\", \"show code\", \"hide code\", \"show prompt\", \"hide prompt\", \"embedding\",\n               \"clustering\", \"labelling\", \"takeaways\", \"overview\"]\n\n    arg_list = arguments['argument'].to_list() + \\\n        labels['label'].to_list() + \\\n        UI_copy + \\\n        languages\n\n    if 'name' in config:\n        arg_list.append(config['name'])\n    if 'question' in config:\n        arg_list.append(config['question'])\n\n    prompt_file = config.get('translation_prompt', 'default')\n    with open(f\"prompts/translation/{prompt_file}.txt\") as f:\n        prompt = f.read()\n    model = config['model']\n\n    config['translation_prompt'] = prompt\n\n    translations = [translate_lang(\n        arg_list, 10, prompt, lang, model) for lang in languages]\n\n    # handling long takeaways differently, WITHOUT batching too much\n    long_arg_list = takeaways['takeaways'].to_list()\n    long_arg_list.append(overview)\n    if 'intro' in config:\n        long_arg_list.append(config['intro'])\n\n    long_translations = [translate_lang(\n        long_arg_list, 1, prompt, lang, model) for lang in languages]\n\n    for i, id in enumerate(arg_list):\n        print('i, id', i, id)\n        results[str(id)] = list([t[i] for t in translations])\n    for i, id in enumerate(long_arg_list):\n        results[str(id)] = list([t[i] for t in long_translations])\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n\n\ndef translate_lang(arg_list, batch_size, prompt, lang, model):\n    translations = []\n    lang_prompt = prompt.replace(\"{language}\", lang)\n    print(f\"Translating to {lang}...\")\n    for i in tqdm(range(0, len(arg_list), batch_size)):\n        batch = arg_list[i: i + batch_size]\n        translations.extend(translate_batch(batch, lang_prompt, model))\n    return translations\n\n\ndef translate_batch(batch, lang_prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = json.dumps(list(batch))\n    response = llm(messages=messages(lang_prompt, input)).content.strip()\n    if \"```\" in response:\n        response = response.split(\"```\")[1]\n    if response.startswith(\"json\"):\n        response = response[4:]\n    try:\n        parsed = [a.strip() for a in json.loads(response)]\n        if len(parsed) != len(batch):\n            print(\"Warning: batch size mismatch!\")\n            print(\"Batch len:\", len(batch))\n            print(\"Response len:\", len(parsed))\n            for i, item in enumerate(batch):\n                print(f\"Batch item {i}:\", item)\n                if (i \u003c len(parsed)):\n                    print(\"Response:\", parsed[i])\n            if (len(batch) \u003e 1):\n                print(\"Retrying with smaller batches...\")\n                mid = len(batch) // 2\n                return translate_batch(batch[:mid], lang_prompt, model, retries - 1) + \\\n                    translate_batch(\n                        batch[mid:], lang_prompt, model, retries - 1)\n            else:\n                print(\"Retrying batch...\")\n                return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            return parsed\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying batch...\")\n            return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            raise e\n","prompt":"/system \n\n[\nあなたはプロの翻訳家です。\n単語や文のリストを受け取ります。\n同じリストを、同じ順番で、{言語}に翻訳して返してください。\nオリジナルのリストと同じ長さの有効なJSON文字列リストを返すようにしてください。\n]"},"intro":"XXXXXXXXXXXXX","output_dir":"my-project","previous":{"name":"Recursive Public, Agenda Setting","question":"新潟の観光地ぽんしゅ館の感想","input":"my-data","model":"gpt-3.5-turbo","extraction":{"workers":3,"limit":12,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    print(f'path:{path}')\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    print(f'comments.columns:{comments.columns}')\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n    print(results.info())\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []\n","prompt":"/system\n\nYou are a professional research assistant and your job is to help \nme prepare a nice and clean datasets of arguments. \n\nThe context is that we have run a public consultation on the \ntopic of artificial intelligence. I'm going to give you examples \nof arguments that were contributed by the public and I want you \nto help me make them more concise and easy to read. When really \nnecessary, you can also break it down into two separate arguments, \nbut it will often be best to return a single arguments. \n\nPlease return the result as a well-formatted JSON list of strings. \n\n/human\n\nAI technologies should be developed with a focus on reducing their own \nenvironmental impact over their lifecycle.\n\n/ai \n\n[\n  \"We should focus on reducing the environmental impact of AI technologies\"\n]\n\n/human \n\nThere should be a concerted effort to educate the public about the \ncapabilities, limitations, and ethical considerations of AI.\n\n/ai \n\n[\n  \"We should educate the public about the capabilities of AI\",\n  \"We should educate the public about the limitations and ethical considerations of AI\"\n]\n\n/human \n\nAI can optimize smart homes and buildings for energy efficiency and occupant wellbeing.\n\n/ ai \n\n[\n  \"AI can optimize smart homes and buildings for energy efficiency and occupant wellbeing.\"\n]\n\n/human \n\nAI can help optimize energy grids, reducing waste and carbon emissions.\n\n/ai \n\n[\n  \"AI could optimize energy grids to reduce waste and carbon emissions.\"\n]\n\n","model":"gpt-3.5-turbo"},"clustering":{"clusters":3,"source_code":"\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4.\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom importlib import import_module\n\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # (!) we import the following modules dynamically for a reason\n    # (they are slow to load and not required for all pipelines)\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    stopwords = import_module('nltk.corpus').stopwords\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module(\n        'sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    stop = stopwords.words(\"english\")\n    vectorizer_model = CountVectorizer(stop_words=stop)\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # Fit the topic model.\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,  # Use the modified n_neighbors\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result\n"},"translation":{"model":"gpt-4","languages":["Japanese"],"flags":[],"source_code":"\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages\nfrom langchain.schema import AIMessage\nimport pandas as pd\nimport json\nfrom tqdm import tqdm\n\n\ndef translation(config):\n\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/translations.json\"\n    results = {}\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) == 0:\n        print(\"No languages specified. Skipping translation step.\")\n        # creating an empty file any, to reduce special casing later\n        with open(path, 'w') as file:\n            json.dump(results, file, indent=2)\n        return\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    with open(f\"outputs/{dataset}/overview.txt\") as f:\n        overview = f.read()\n\n    UI_copy = [\"Argument\", \"Original comment\", \"Representative arguments\",\n               \"Open full-screen map\", \"Back to report\", \"Hide labels\", \"Show labels\",\n               \"Show filters\", \"Hide filters\", \"Min. votes\", \"Consensus\",\n               \"Showing\", \"arguments\", \"Reset zoom\", \"Click anywhere on the map to close this\",\n               \"Click on the dot for details\",\n               \"agree\", \"disagree\", \"Language\", \"English\", \"arguments\", \"of total\",\n               \"Overview\", \"Cluster analysis\", \"Representative comments\", \"Introduction\",\n               \"Clusters\", \"Appendix\", \"This report was generated using an AI pipeline that consists of the following steps\",\n               \"Step\", \"extraction\", \"show code\", \"hide code\", \"show prompt\", \"hide prompt\", \"embedding\",\n               \"clustering\", \"labelling\", \"takeaways\", \"overview\"]\n\n    arg_list = arguments['argument'].to_list() + \\\n        labels['label'].to_list() + \\\n        UI_copy + \\\n        languages\n\n    if 'name' in config:\n        arg_list.append(config['name'])\n    if 'question' in config:\n        arg_list.append(config['question'])\n\n    prompt_file = config.get('translation_prompt', 'default')\n    with open(f\"prompts/translation/{prompt_file}.txt\") as f:\n        prompt = f.read()\n    model = config['model']\n\n    config['translation_prompt'] = prompt\n\n    translations = [translate_lang(\n        arg_list, 10, prompt, lang, model) for lang in languages]\n\n    # handling long takeaways differently, WITHOUT batching too much\n    long_arg_list = takeaways['takeaways'].to_list()\n    long_arg_list.append(overview)\n    if 'intro' in config:\n        long_arg_list.append(config['intro'])\n\n    long_translations = [translate_lang(\n        long_arg_list, 1, prompt, lang, model) for lang in languages]\n\n    for i, id in enumerate(arg_list):\n        print('i, id', i, id)\n        results[str(id)] = list([t[i] for t in translations])\n    for i, id in enumerate(long_arg_list):\n        results[str(id)] = list([t[i] for t in long_translations])\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n\n\ndef translate_lang(arg_list, batch_size, prompt, lang, model):\n    translations = []\n    lang_prompt = prompt.replace(\"{language}\", lang)\n    print(f\"Translating to {lang}...\")\n    for i in tqdm(range(0, len(arg_list), batch_size)):\n        batch = arg_list[i: i + batch_size]\n        translations.extend(translate_batch(batch, lang_prompt, model))\n    return translations\n\n\ndef translate_batch(batch, lang_prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = json.dumps(list(batch))\n    response = llm(messages=messages(lang_prompt, input)).content.strip()\n    if \"```\" in response:\n        response = response.split(\"```\")[1]\n    if response.startswith(\"json\"):\n        response = response[4:]\n    try:\n        parsed = [a.strip() for a in json.loads(response)]\n        if len(parsed) != len(batch):\n            print(\"Warning: batch size mismatch!\")\n            print(\"Batch len:\", len(batch))\n            print(\"Response len:\", len(parsed))\n            for i, item in enumerate(batch):\n                print(f\"Batch item {i}:\", item)\n                if (i \u003c len(parsed)):\n                    print(\"Response:\", parsed[i])\n            if (len(batch) \u003e 1):\n                print(\"Retrying with smaller batches...\")\n                mid = len(batch) // 2\n                return translate_batch(batch[:mid], lang_prompt, model, retries - 1) + \\\n                    translate_batch(\n                        batch[mid:], lang_prompt, model, retries - 1)\n            else:\n                print(\"Retrying batch...\")\n                return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            return parsed\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying batch...\")\n            return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            raise e\n","prompt":"/system \n\n[\nあなたはプロの翻訳家です。\n単語や文のリストを受け取ります。\n同じリストを、同じ順番で、{言語}に翻訳して返してください。\nオリジナルのリストと同じ長さの有効なJSON文字列リストを返すようにしてください。\n]"},"intro":"XXXXXXXXXXXXX","output_dir":"my-project","embedding":{"source_code":"\nfrom langchain.embeddings import OpenAIEmbeddings\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"},"labelling":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nYou are a category labeling assistant that generates a category label \nfor a set of arguments within a broader consultation. You are given the main question \nof the consultation, list of arguments inside the cluster, and a list of arguments \noutside this cluster. You answer with a single category label that summarizes the \ncluster. \n\nYou do not include context that is already obvious from the question (for example: \nif the question of the consultation is something like \"what challenges are you facing \nin France\", there is no need to repeat \"in France\" in the cluster label).\n\nThe label must be very concise and just precise enough to capture what distinguishes \nthe cluster from the arguments found outside. \n\n/human\n\nQuestion of the consultation: \"What do you think has been the impact of the UK decision to leave the EU?\"\n\nExamples of arguments OUTSIDE the cluster of interest:\n\n * We faced limitations in educational and cultural exchange opportunities due to exclusion from the Erasmus program.\n * The UK dealt with longer travel times caused by increased border checks, affecting commuters and vacationers.\n * We saw reduced cooperation in environmental standards, hindering efforts to combat climate change.\n * I experienced challenges in patient care due to disruptions in reciprocal healthcare agreements.\n * We faced complexity in residency and citizenship applications for families due to Brexit-related changes.\n * The UK witnessed hindrance in global efforts to address research challenges due to reduced collaboration opportunities.\n * We faced limitations in creative projects due to exclusion from EU cultural funding programs.\n * The UK witnessed setbacks in charitable initiatives and community support due to the loss of EU funding.\n * We experienced challenges in cross-border dispute resolution due to weakened consumer protections.\n * The UK faced limitations in touring EU countries as professional musicians, impacting careers.\n\nExamples of arguments inside the cluster:\n\n * We experienced supply chain disruptions due to Brexit, leading to increased costs and delayed deliveries for businesses.\n * I faced market fluctuations and uncertainties in investments and retirement savings because of Brexit.\n * The UK dealt with reduced profit margins as an exporter due to new tariffs and customs procedures.\n * We lost jobs because companies relocated operations to stay within the EU market post-Brexit.\n * The UK struggled with the increased cost of living caused by skyrocketing prices of imported goods.\n * We witnessed a decline in investment in the UK tech sector, impacting innovation and job opportunities.\n * The UK saw a decline in tourism due to new visa regulations, affecting hospitality businesses.\n * I experienced reduced purchasing power and increased travel expenses due to the drop in the pound's value.\n\n/ai \n\nNegative Financial Impact\n","model":"gpt-3.5-turbo"},"takeaways":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nYou are an expert research assistant working in a think tank. You will be given a list of arguments that have been made by a cluster of participants during a public consultation. You respond with one or two paragraphs summarizing your main takeaways. You are very concise and write short, snappy sentences which are easy to read. \n \n/human\n\n[\n  \"I firmly believe that gun violence constitutes a severe public health crisis in our society.\",\n  \"We need to address this issue urgently through comprehensive gun control measures.\", \n  \"I support the implementation of universal background checks for all gun buyers\",\n  \"I am in favor of banning assault weapons and high-capacity magazines.\",\n  \"I advocate for stricter regulations to prevent illegal gun trafficking.\",\n  \"Mental health evaluations should be a mandatory part of the gun purchasing process.\"\n]\n\n/ai \n\nParticipants called for comprehensive gun control, emphasizing universal background checks, assault weapon bans, curbing illegal gun trafficking, and prioritizing mental health evaluations.","model":"gpt-3.5-turbo"},"overview":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)\n","prompt":"/system \n\nあなたはシンクタンクで働く研究アシスタントの専門家です。チームは特定のトピックについての公開協議を実施し、さまざまな選択肢のクラスターを分析し始めました。今から、各クラスターの簡単な分析とともにクラスターのリストを受け取ります。あなたの仕事は、その調査結果の短い要約を返すことです。要約は非常に簡潔でなければならず（最大で1段落、4文以内）、陳腐な表現は避ける必要があります。","model":"gpt-3.5-turbo"},"aggregation":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"translations\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) \u003e 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"},"visualization":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"},"plan":[{"step":"extraction","run":false,"reason":"nothing changed"},{"step":"embedding","run":false,"reason":"nothing changed"},{"step":"clustering","run":false,"reason":"nothing changed"},{"step":"labelling","run":false,"reason":"nothing changed"},{"step":"takeaways","run":false,"reason":"nothing changed"},{"step":"overview","run":true,"reason":"some parameters changed: prompt"},{"step":"translation","run":true,"reason":"some dependent steps will re-run: overview"},{"step":"aggregation","run":true,"reason":"some dependent steps will re-run: overview, translation"},{"step":"visualization","run":true,"reason":"some dependent steps will re-run: aggregation"}],"status":"completed","start_time":"2024-06-17T17:27:49.847450","completed_jobs":[{"step":"overview","completed":"2024-06-17T17:27:51.382930","duration":1.532751,"params":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)\n","prompt":"/system \n\nあなたはシンクタンクで働く研究アシスタントの専門家です。チームは特定のトピックについての公開協議を実施し、さまざまな選択肢のクラスターを分析し始めました。今から、各クラスターの簡単な分析とともにクラスターのリストを受け取ります。あなたの仕事は、その調査結果の短い要約を返すことです。要約は非常に簡潔でなければならず（最大で1段落、4文以内）、陳腐な表現は避ける必要があります。","model":"gpt-3.5-turbo"}},{"step":"translation","completed":"2024-06-17T17:28:16.324813","duration":24.940717,"params":{"model":"gpt-4","languages":["Japanese"],"flags":[],"source_code":"\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages\nfrom langchain.schema import AIMessage\nimport pandas as pd\nimport json\nfrom tqdm import tqdm\n\n\ndef translation(config):\n\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/translations.json\"\n    results = {}\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) == 0:\n        print(\"No languages specified. Skipping translation step.\")\n        # creating an empty file any, to reduce special casing later\n        with open(path, 'w') as file:\n            json.dump(results, file, indent=2)\n        return\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    with open(f\"outputs/{dataset}/overview.txt\") as f:\n        overview = f.read()\n\n    UI_copy = [\"Argument\", \"Original comment\", \"Representative arguments\",\n               \"Open full-screen map\", \"Back to report\", \"Hide labels\", \"Show labels\",\n               \"Show filters\", \"Hide filters\", \"Min. votes\", \"Consensus\",\n               \"Showing\", \"arguments\", \"Reset zoom\", \"Click anywhere on the map to close this\",\n               \"Click on the dot for details\",\n               \"agree\", \"disagree\", \"Language\", \"English\", \"arguments\", \"of total\",\n               \"Overview\", \"Cluster analysis\", \"Representative comments\", \"Introduction\",\n               \"Clusters\", \"Appendix\", \"This report was generated using an AI pipeline that consists of the following steps\",\n               \"Step\", \"extraction\", \"show code\", \"hide code\", \"show prompt\", \"hide prompt\", \"embedding\",\n               \"clustering\", \"labelling\", \"takeaways\", \"overview\"]\n\n    arg_list = arguments['argument'].to_list() + \\\n        labels['label'].to_list() + \\\n        UI_copy + \\\n        languages\n\n    if 'name' in config:\n        arg_list.append(config['name'])\n    if 'question' in config:\n        arg_list.append(config['question'])\n\n    prompt_file = config.get('translation_prompt', 'default')\n    with open(f\"prompts/translation/{prompt_file}.txt\") as f:\n        prompt = f.read()\n    model = config['model']\n\n    config['translation_prompt'] = prompt\n\n    translations = [translate_lang(\n        arg_list, 10, prompt, lang, model) for lang in languages]\n\n    # handling long takeaways differently, WITHOUT batching too much\n    long_arg_list = takeaways['takeaways'].to_list()\n    long_arg_list.append(overview)\n    if 'intro' in config:\n        long_arg_list.append(config['intro'])\n\n    long_translations = [translate_lang(\n        long_arg_list, 1, prompt, lang, model) for lang in languages]\n\n    for i, id in enumerate(arg_list):\n        print('i, id', i, id)\n        results[str(id)] = list([t[i] for t in translations])\n    for i, id in enumerate(long_arg_list):\n        results[str(id)] = list([t[i] for t in long_translations])\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n\n\ndef translate_lang(arg_list, batch_size, prompt, lang, model):\n    translations = []\n    lang_prompt = prompt.replace(\"{language}\", lang)\n    print(f\"Translating to {lang}...\")\n    for i in tqdm(range(0, len(arg_list), batch_size)):\n        batch = arg_list[i: i + batch_size]\n        translations.extend(translate_batch(batch, lang_prompt, model))\n    return translations\n\n\ndef translate_batch(batch, lang_prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = json.dumps(list(batch))\n    response = llm(messages=messages(lang_prompt, input)).content.strip()\n    if \"```\" in response:\n        response = response.split(\"```\")[1]\n    if response.startswith(\"json\"):\n        response = response[4:]\n    try:\n        parsed = [a.strip() for a in json.loads(response)]\n        if len(parsed) != len(batch):\n            print(\"Warning: batch size mismatch!\")\n            print(\"Batch len:\", len(batch))\n            print(\"Response len:\", len(parsed))\n            for i, item in enumerate(batch):\n                print(f\"Batch item {i}:\", item)\n                if (i \u003c len(parsed)):\n                    print(\"Response:\", parsed[i])\n            if (len(batch) \u003e 1):\n                print(\"Retrying with smaller batches...\")\n                mid = len(batch) // 2\n                return translate_batch(batch[:mid], lang_prompt, model, retries - 1) + \\\n                    translate_batch(\n                        batch[mid:], lang_prompt, model, retries - 1)\n            else:\n                print(\"Retrying batch...\")\n                return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            return parsed\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying batch...\")\n            return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            raise e\n","prompt":"/system \n\n[\nあなたはプロの翻訳家です。\n単語や文のリストを受け取ります。\n同じリストを、同じ順番で、{言語}に翻訳して返してください。\nオリジナルのリストと同じ長さの有効なJSON文字列リストを返すようにしてください。\n]"}},{"step":"aggregation","completed":"2024-06-17T17:28:16.359689","duration":0.032478,"params":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"translations\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) \u003e 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"}},{"step":"visualization","completed":"2024-06-17T17:28:20.373642","duration":4.013047,"params":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"}}],"lock_until":"2024-06-17T17:33:20.374581","current_job":"visualization","current_job_started":"2024-06-17T17:28:16.360622","translation_prompt":"/system \n\n[\nあなたはプロの翻訳家です。\n単語や文のリストを受け取ります。\n同じリストを、同じ順番で、{言語}に翻訳して返してください。\nオリジナルのリストと同じ長さの有効なJSON文字列リストを返すようにしてください。\n]","previously_completed_jobs":[{"step":"extraction","completed":"2024-06-17T16:23:32.577199","duration":20.694657,"params":{"workers":3,"limit":12,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    print(f'path:{path}')\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    print(f'comments.columns:{comments.columns}')\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []\n","prompt":"/system\n\nYou are a professional research assistant and your job is to help \nme prepare a nice and clean datasets of arguments. \n\nThe context is that we have run a public consultation on the \ntopic of artificial intelligence. I'm going to give you examples \nof arguments that were contributed by the public and I want you \nto help me make them more concise and easy to read. When really \nnecessary, you can also break it down into two separate arguments, \nbut it will often be best to return a single arguments. \n\nPlease return the result as a well-formatted JSON list of strings. \n\n/human\n\nAI technologies should be developed with a focus on reducing their own \nenvironmental impact over their lifecycle.\n\n/ai \n\n[\n  \"We should focus on reducing the environmental impact of AI technologies\"\n]\n\n/human \n\nThere should be a concerted effort to educate the public about the \ncapabilities, limitations, and ethical considerations of AI.\n\n/ai \n\n[\n  \"We should educate the public about the capabilities of AI\",\n  \"We should educate the public about the limitations and ethical considerations of AI\"\n]\n\n/human \n\nAI can optimize smart homes and buildings for energy efficiency and occupant wellbeing.\n\n/ ai \n\n[\n  \"AI can optimize smart homes and buildings for energy efficiency and occupant wellbeing.\"\n]\n\n/human \n\nAI can help optimize energy grids, reducing waste and carbon emissions.\n\n/ai \n\n[\n  \"AI could optimize energy grids to reduce waste and carbon emissions.\"\n]\n\n","model":"gpt-3.5-turbo"}},{"step":"embedding","completed":"2024-06-17T16:23:37.277278","duration":4.698366,"params":{"source_code":"\nfrom langchain.embeddings import OpenAIEmbeddings\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"}},{"step":"clustering","completed":"2024-06-17T16:24:09.063166","duration":31.784141,"params":{"clusters":3,"source_code":"\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4.\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom importlib import import_module\n\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # (!) we import the following modules dynamically for a reason\n    # (they are slow to load and not required for all pipelines)\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    stopwords = import_module('nltk.corpus').stopwords\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module(\n        'sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    stop = stopwords.words(\"english\")\n    vectorizer_model = CountVectorizer(stop_words=stop)\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # Fit the topic model.\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,  # Use the modified n_neighbors\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result\n"}},{"step":"labelling","completed":"2024-06-17T16:24:11.818974","duration":2.7544,"params":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nYou are a category labeling assistant that generates a category label \nfor a set of arguments within a broader consultation. You are given the main question \nof the consultation, list of arguments inside the cluster, and a list of arguments \noutside this cluster. You answer with a single category label that summarizes the \ncluster. \n\nYou do not include context that is already obvious from the question (for example: \nif the question of the consultation is something like \"what challenges are you facing \nin France\", there is no need to repeat \"in France\" in the cluster label).\n\nThe label must be very concise and just precise enough to capture what distinguishes \nthe cluster from the arguments found outside. \n\n/human\n\nQuestion of the consultation: \"What do you think has been the impact of the UK decision to leave the EU?\"\n\nExamples of arguments OUTSIDE the cluster of interest:\n\n * We faced limitations in educational and cultural exchange opportunities due to exclusion from the Erasmus program.\n * The UK dealt with longer travel times caused by increased border checks, affecting commuters and vacationers.\n * We saw reduced cooperation in environmental standards, hindering efforts to combat climate change.\n * I experienced challenges in patient care due to disruptions in reciprocal healthcare agreements.\n * We faced complexity in residency and citizenship applications for families due to Brexit-related changes.\n * The UK witnessed hindrance in global efforts to address research challenges due to reduced collaboration opportunities.\n * We faced limitations in creative projects due to exclusion from EU cultural funding programs.\n * The UK witnessed setbacks in charitable initiatives and community support due to the loss of EU funding.\n * We experienced challenges in cross-border dispute resolution due to weakened consumer protections.\n * The UK faced limitations in touring EU countries as professional musicians, impacting careers.\n\nExamples of arguments inside the cluster:\n\n * We experienced supply chain disruptions due to Brexit, leading to increased costs and delayed deliveries for businesses.\n * I faced market fluctuations and uncertainties in investments and retirement savings because of Brexit.\n * The UK dealt with reduced profit margins as an exporter due to new tariffs and customs procedures.\n * We lost jobs because companies relocated operations to stay within the EU market post-Brexit.\n * The UK struggled with the increased cost of living caused by skyrocketing prices of imported goods.\n * We witnessed a decline in investment in the UK tech sector, impacting innovation and job opportunities.\n * The UK saw a decline in tourism due to new visa regulations, affecting hospitality businesses.\n * I experienced reduced purchasing power and increased travel expenses due to the drop in the pound's value.\n\n/ai \n\nNegative Financial Impact\n","model":"gpt-3.5-turbo"}},{"step":"takeaways","completed":"2024-06-17T16:24:16.390492","duration":4.569402,"params":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nYou are an expert research assistant working in a think tank. You will be given a list of arguments that have been made by a cluster of participants during a public consultation. You respond with one or two paragraphs summarizing your main takeaways. You are very concise and write short, snappy sentences which are easy to read. \n \n/human\n\n[\n  \"I firmly believe that gun violence constitutes a severe public health crisis in our society.\",\n  \"We need to address this issue urgently through comprehensive gun control measures.\", \n  \"I support the implementation of universal background checks for all gun buyers\",\n  \"I am in favor of banning assault weapons and high-capacity magazines.\",\n  \"I advocate for stricter regulations to prevent illegal gun trafficking.\",\n  \"Mental health evaluations should be a mandatory part of the gun purchasing process.\"\n]\n\n/ai \n\nParticipants called for comprehensive gun control, emphasizing universal background checks, assault weapon bans, curbing illegal gun trafficking, and prioritizing mental health evaluations.","model":"gpt-3.5-turbo"}}],"end_time":"2024-06-17T17:28:20.374576"},"embedding":{"source_code":"\nfrom langchain.embeddings import OpenAIEmbeddings\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"},"labelling":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nYou are a category labeling assistant that generates a category label \nfor a set of arguments within a broader consultation. You are given the main question \nof the consultation, list of arguments inside the cluster, and a list of arguments \noutside this cluster. You answer with a single category label that summarizes the \ncluster. \n\nYou do not include context that is already obvious from the question (for example: \nif the question of the consultation is something like \"what challenges are you facing \nin France\", there is no need to repeat \"in France\" in the cluster label).\n\nThe label must be very concise and just precise enough to capture what distinguishes \nthe cluster from the arguments found outside. \n\n/human\n\nQuestion of the consultation: \"What do you think has been the impact of the UK decision to leave the EU?\"\n\nExamples of arguments OUTSIDE the cluster of interest:\n\n * We faced limitations in educational and cultural exchange opportunities due to exclusion from the Erasmus program.\n * The UK dealt with longer travel times caused by increased border checks, affecting commuters and vacationers.\n * We saw reduced cooperation in environmental standards, hindering efforts to combat climate change.\n * I experienced challenges in patient care due to disruptions in reciprocal healthcare agreements.\n * We faced complexity in residency and citizenship applications for families due to Brexit-related changes.\n * The UK witnessed hindrance in global efforts to address research challenges due to reduced collaboration opportunities.\n * We faced limitations in creative projects due to exclusion from EU cultural funding programs.\n * The UK witnessed setbacks in charitable initiatives and community support due to the loss of EU funding.\n * We experienced challenges in cross-border dispute resolution due to weakened consumer protections.\n * The UK faced limitations in touring EU countries as professional musicians, impacting careers.\n\nExamples of arguments inside the cluster:\n\n * We experienced supply chain disruptions due to Brexit, leading to increased costs and delayed deliveries for businesses.\n * I faced market fluctuations and uncertainties in investments and retirement savings because of Brexit.\n * The UK dealt with reduced profit margins as an exporter due to new tariffs and customs procedures.\n * We lost jobs because companies relocated operations to stay within the EU market post-Brexit.\n * The UK struggled with the increased cost of living caused by skyrocketing prices of imported goods.\n * We witnessed a decline in investment in the UK tech sector, impacting innovation and job opportunities.\n * The UK saw a decline in tourism due to new visa regulations, affecting hospitality businesses.\n * I experienced reduced purchasing power and increased travel expenses due to the drop in the pound's value.\n\n/ai \n\nNegative Financial Impact\n","model":"gpt-3.5-turbo"},"takeaways":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nYou are an expert research assistant working in a think tank. You will be given a list of arguments that have been made by a cluster of participants during a public consultation. You respond with one or two paragraphs summarizing your main takeaways. You are very concise and write short, snappy sentences which are easy to read. \n \n/human\n\n[\n  \"I firmly believe that gun violence constitutes a severe public health crisis in our society.\",\n  \"We need to address this issue urgently through comprehensive gun control measures.\", \n  \"I support the implementation of universal background checks for all gun buyers\",\n  \"I am in favor of banning assault weapons and high-capacity magazines.\",\n  \"I advocate for stricter regulations to prevent illegal gun trafficking.\",\n  \"Mental health evaluations should be a mandatory part of the gun purchasing process.\"\n]\n\n/ai \n\nParticipants called for comprehensive gun control, emphasizing universal background checks, assault weapon bans, curbing illegal gun trafficking, and prioritizing mental health evaluations.","model":"gpt-3.5-turbo"},"overview":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)\n","prompt":"/system \n\nあなたはシンクタンクで働く研究アシスタントの専門家です。\nチームは特定のトピックについての公開協議を実施し、さまざまな選択肢のクラスターを分析し始めました。\n今から、各クラスターの簡単な分析とともにクラスターのリストを受け取ります。あなたの仕事は、その調査結果の短い日本語の要約を返すことです。\n要約は非常に簡潔でなければならず（最大で1段落、4文以内）、陳腐な表現は避ける必要があります。","model":"gpt-3.5-turbo"},"aggregation":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"translations\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) \u003e 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"},"visualization":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"},"plan":[{"step":"extraction","run":false,"reason":"nothing changed"},{"step":"embedding","run":false,"reason":"nothing changed"},{"step":"clustering","run":false,"reason":"nothing changed"},{"step":"labelling","run":false,"reason":"nothing changed"},{"step":"takeaways","run":false,"reason":"nothing changed"},{"step":"overview","run":true,"reason":"some parameters changed: prompt"},{"step":"translation","run":true,"reason":"some dependent steps will re-run: overview"},{"step":"aggregation","run":true,"reason":"some dependent steps will re-run: overview, translation"},{"step":"visualization","run":true,"reason":"some dependent steps will re-run: aggregation"}],"status":"running","start_time":"2024-06-19T10:00:43.992805","completed_jobs":[{"step":"overview","completed":"2024-06-19T10:00:48.401663","duration":4.401894,"params":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)\n","prompt":"/system \n\nあなたはシンクタンクで働く研究アシスタントの専門家です。\nチームは特定のトピックについての公開協議を実施し、さまざまな選択肢のクラスターを分析し始めました。\n今から、各クラスターの簡単な分析とともにクラスターのリストを受け取ります。あなたの仕事は、その調査結果の短い日本語の要約を返すことです。\n要約は非常に簡潔でなければならず（最大で1段落、4文以内）、陳腐な表現は避ける必要があります。","model":"gpt-3.5-turbo"}},{"step":"translation","completed":"2024-06-19T10:01:16.278317","duration":27.875201,"params":{"model":"gpt-4","languages":["Japanese"],"flags":[],"source_code":"\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages\nfrom langchain.schema import AIMessage\nimport pandas as pd\nimport json\nfrom tqdm import tqdm\n\n\ndef translation(config):\n\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/translations.json\"\n    results = {}\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) == 0:\n        print(\"No languages specified. Skipping translation step.\")\n        # creating an empty file any, to reduce special casing later\n        with open(path, 'w') as file:\n            json.dump(results, file, indent=2)\n        return\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    with open(f\"outputs/{dataset}/overview.txt\") as f:\n        overview = f.read()\n\n    UI_copy = [\"Argument\", \"Original comment\", \"Representative arguments\",\n               \"Open full-screen map\", \"Back to report\", \"Hide labels\", \"Show labels\",\n               \"Show filters\", \"Hide filters\", \"Min. votes\", \"Consensus\",\n               \"Showing\", \"arguments\", \"Reset zoom\", \"Click anywhere on the map to close this\",\n               \"Click on the dot for details\",\n               \"agree\", \"disagree\", \"Language\", \"English\", \"arguments\", \"of total\",\n               \"Overview\", \"Cluster analysis\", \"代表的なコメント\", \"Introduction\",\n               \"Clusters\", \"Appendix\", \"This report was generated using an AI pipeline that consists of the following steps\",\n               \"Step\", \"extraction\", \"show code\", \"hide code\", \"show prompt\", \"hide prompt\", \"embedding\",\n               \"clustering\", \"labelling\", \"takeaways\", \"overview\"]\n\n    arg_list = arguments['argument'].to_list() + \\\n        labels['label'].to_list() + \\\n        UI_copy + \\\n        languages\n\n    if 'name' in config:\n        arg_list.append(config['name'])\n    if 'question' in config:\n        arg_list.append(config['question'])\n\n    prompt_file = config.get('translation_prompt', 'default')\n    with open(f\"prompts/translation/{prompt_file}.txt\") as f:\n        prompt = f.read()\n    model = config['model']\n\n    config['translation_prompt'] = prompt\n\n    translations = [translate_lang(\n        arg_list, 10, prompt, lang, model) for lang in languages]\n\n    # handling long takeaways differently, WITHOUT batching too much\n    long_arg_list = takeaways['takeaways'].to_list()\n    long_arg_list.append(overview)\n    if 'intro' in config:\n        long_arg_list.append(config['intro'])\n\n    long_translations = [translate_lang(\n        long_arg_list, 1, prompt, lang, model) for lang in languages]\n\n    for i, id in enumerate(arg_list):\n        print('i, id', i, id)\n        results[str(id)] = list([t[i] for t in translations])\n    for i, id in enumerate(long_arg_list):\n        results[str(id)] = list([t[i] for t in long_translations])\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n\n\ndef translate_lang(arg_list, batch_size, prompt, lang, model):\n    translations = []\n    lang_prompt = prompt.replace(\"{language}\", lang)\n    print(f\"Translating to {lang}...\")\n    for i in tqdm(range(0, len(arg_list), batch_size)):\n        batch = arg_list[i: i + batch_size]\n        translations.extend(translate_batch(batch, lang_prompt, model))\n    return translations\n\n\ndef translate_batch(batch, lang_prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = json.dumps(list(batch))\n    response = llm(messages=messages(lang_prompt, input)).content.strip()\n    if \"```\" in response:\n        response = response.split(\"```\")[1]\n    if response.startswith(\"json\"):\n        response = response[4:]\n    try:\n        parsed = [a.strip() for a in json.loads(response)]\n        if len(parsed) != len(batch):\n            print(\"Warning: batch size mismatch!\")\n            print(\"Batch len:\", len(batch))\n            print(\"Response len:\", len(parsed))\n            for i, item in enumerate(batch):\n                print(f\"Batch item {i}:\", item)\n                if (i \u003c len(parsed)):\n                    print(\"Response:\", parsed[i])\n            if (len(batch) \u003e 1):\n                print(\"Retrying with smaller batches...\")\n                mid = len(batch) // 2\n                return translate_batch(batch[:mid], lang_prompt, model, retries - 1) + \\\n                    translate_batch(\n                        batch[mid:], lang_prompt, model, retries - 1)\n            else:\n                print(\"Retrying batch...\")\n                return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            return parsed\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying batch...\")\n            return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            raise e\n","prompt":"/system \n\n[\nあなたはプロの翻訳家です。\n単語や文のリストを受け取ります。\n同じリストを、同じ順番で、{言語}に翻訳して返してください。\nオリジナルのリストと同じ長さの有効なJSON文字列リストを返すようにしてください。\n]"}}],"lock_until":"2024-06-19T10:06:16.280133","current_job":"aggregation","current_job_started":"2024-06-19T10:01:16.280120","translation_prompt":"/system \n\n[\nあなたはプロの翻訳家です。\n単語や文のリストを受け取ります。\n同じリストを、同じ順番で、{言語}に翻訳して返してください。\nオリジナルのリストと同じ長さの有効なJSON文字列リストを返すようにしてください。\n]"}}},"__N_SSG":true},"page":"/","query":{},"buildId":"htPe964IuNE2A3C31Qq2H","assetPrefix":".","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>