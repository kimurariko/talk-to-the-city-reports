{
  "name": "\u65b0\u6f5f\u306e\u89b3\u5149\u5730",
  "question": "\u307d\u3093\u3057\u3085\u9928\u306e\u9b45\u529b",
  "input": "my-data",
  "model": "gpt-4",
  "extraction": {
    "workers": 11,
    "limit": 50,
    "source_code": "import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\ndef extraction(config):\n    # \u51fa\u529b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3068\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u306e\u8a2d\u5b9a\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n\n    # \u5165\u529b\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30b3\u30e1\u30f3\u30c8\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    \n    # \u30e2\u30c7\u30eb\u3001\u30d7\u30ed\u30f3\u30d7\u30c8\u3001\u30ef\u30fc\u30ab\u30fc\u6570\u3001\u5236\u9650\u6570\u306e\u8a2d\u5b9a\u3092\u53d6\u5f97\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    # \u30b3\u30e1\u30f3\u30c8ID\u3092\u53d6\u5f97\u3057\u3001\u30b3\u30e1\u30f3\u30c8ID\u3092\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306b\u8a2d\u5b9a\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n\n    # \u30b3\u30e1\u30f3\u30c8\u3092\u30d0\u30c3\u30c1\u306b\u5206\u5272\u3057\u3066\u51e6\u7406\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        \n        # \u30d0\u30c3\u30c1\u3054\u3068\u306e\u7d50\u679c\u3092DataFrame\u306b\u8ffd\u52a0\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \n                           \"categoryLabel\": comments.loc[comment_id]['labels'],\n                           \"kutikomi_unique\":comments.loc[comment_id]['kutikomi_unique'],\n                           \"koushiki_unique\":comments.loc[comment_id]['koushiki_unique'],\n                           \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    \n    # \u7d50\u679c\u3092CSV\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\n    results.to_csv(path, index=False)\n\ndef extract_batch(batch, prompt, model, workers):\n    # \u30b9\u30ec\u30c3\u30c9\u30d7\u30fc\u30eb\u3092\u4f7f\u7528\u3057\u3066\u30d0\u30c3\u30c1\u51e6\u7406\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\ndef extract_arguments(input, prompt, model, retries=3):\n    # LLM\uff08\u5927\u898f\u6a21\u8a00\u8a9e\u30e2\u30c7\u30eb\uff09\u3092\u4f7f\u7528\u3057\u3066\u5f15\u6570\u3092\u62bd\u51fa\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        # \u30ec\u30b9\u30dd\u30f3\u30b9\u3092JSON\u3068\u3057\u3066\u30d1\u30fc\u30b9\n        obj = json.loads(response)\n        # \u6587\u5b57\u5217\u306e\u5834\u5408\u3001\u30ea\u30b9\u30c8\u306b\u5909\u63db\n        if isinstance(obj, str):\n            obj = [obj]\n        # \u7a7a\u6587\u5b57\u5217\u3092\u9664\u5916\n        items = [a.strip() for a in obj]\n        items = filter(None, items)\n        return items\n    except json.decoder.JSONDecodeError as e:\n        # JSON\u30d1\u30fc\u30b9\u30a8\u30e9\u30fc\u6642\u306e\u51e6\u7406\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries > 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []\n",
    "prompt": "/system\n\n\n\u3042\u306a\u305f\u306f\u30d7\u30ed\u306e\u30ea\u30b5\u30fc\u30c1\u30fb\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3067\u3001\u79c1\u306e\u4ed5\u4e8b\u3092\u624b\u4f1d\u3046\u3053\u3068\u304c\u3042\u306a\u305f\u306e\u4ed5\u4e8b\u3067\u3059\u3002\n\u79c1\u306e\u4ed5\u4e8b\u306f\u3001\u8ad6\u70b9\u3092\u6574\u7406\u3057\u305f\u304d\u308c\u3044\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f5c\u6210\u3059\u308b\u3053\u3068\u3067\u3059\u3002\n\n\u3053\u308c\u304b\u3089\u4e0e\u3048\u308b\u6295\u7a3f\u3092\u3088\u308a\u7c21\u6f54\u3067\u8aad\u307f\u3084\u3059\u3044\u610f\u898b\u306b\u3059\u308b\u306e\u3092\u624b\u4f1d\u3063\u3066\u307b\u3057\u3044\u3002\n\u672c\u5f53\u306b\u5fc5\u8981\u306a\u5834\u5408\u306f\u30012\u3064\u4ee5\u4e0a\u306e\u5225\u3005\u306e\u610f\u898b\u306b\u5206\u3051\u308b\u3053\u3068\u3082\u3067\u304d\u308b\u304c\u30011\u3064\u306e\u30c8\u30d4\u30c3\u30af\u3092\u8fd4\u3059\u306e\u304c\u6700\u5584\u3067\u3042\u308b\u3053\u3068\u304c\u591a\u3044\u3060\u308d\u3046\u3002\n\u8981\u7d04\u304c\u96e3\u3057\u3044\u5834\u5408\u306f\u3001\u305d\u306e\u307e\u307e\u306e\u6587\u7ae0\u3092\u8fd4\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u4ee5\u4e0b\u306b\u30dd\u30b9\u30c8\u3092\u8981\u7d04\u3059\u308b\u969b\u306e\u4e8b\u4f8b\u3092\u6319\u3052\u307e\u3059\u3002\n\u3053\u308c\u3089\u306f\u3042\u304f\u307e\u3067\u6587\u8108\u306e\u5207\u308a\u96e2\u3055\u308c\u305f\u4f8b\u3067\u3042\u308a\u3001\u3053\u306e\u4f8b\u3067\u4e0e\u3048\u305f\u6587\u7ae0\u3092\u8fd4\u3059\u3053\u3068\u306f\u3057\u306a\u3044\u3067\u304f\u3060\u3055\u3044\u3002\n\n\u7d50\u679c\u306f\u3001\u304d\u3061\u3093\u3068\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3055\u308c\u305f\u6587\u5b57\u5217\u5f62\u5f0f\uff08strings\uff09\u306eJSON\u30ea\u30b9\u30c8\u3068\u3057\u3066\u8fd4\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n/human\n\n\u6c17\u5019\u5909\u52d5\u3092\u8003\u616e\u3057\u305f\u3055\u3089\u306a\u308b\u98a8\u6c34\u5bb3\u5bfe\u7b56\u306e\u5f37\u5316\u306b\u3064\u3044\u3066\u3001\u90fd\u306e\u5177\u4f53\u7684\u306a\u8a08\u753b\u3092\u304a\u4f3a\u3044\u3057\u307e\u3059\u3002\n\n/ai \n\n[\n  \"\u6c17\u5019\u5909\u52d5\u3092\u8003\u616e\u3057\u305f\u3055\u3089\u306a\u308b\u98a8\u6c34\u5bb3\u5bfe\u7b56\u306e\u5f37\u5316\u3057\u3066\u307b\u3057\u3044\u3002\"\n]\n\n/human \n\n\u8c6a\u96e8\u5bfe\u7b56\u5168\u822c\u306e\u57fa\u672c\u65b9\u91dd\u306e\u691c\u8a0e\u3092\u9032\u3081\u308b\u4e2d\u3001\u5177\u4f53\u7684\u306b\u3069\u306e\u3088\u3046\u306a\u65bd\u7b56\u3092\u4f5c\u3063\u3066\u307b\u3057\u3044\u3002\n\n/ai \n\n[\n  \"\u8c6a\u96e8\u5bfe\u7b56\u5168\u822c\u306e\u57fa\u672c\u65b9\u91dd\u306e\u5177\u4f53\u7684\u306a\u65bd\u7b56\u3092\u4f5c\u3063\u3066\u307b\u3057\u3044\u3002\",\n]\n\n/human\n\nAI\u6280\u8853\u306f\u3001\u305d\u306e\u30e9\u30a4\u30d5\u30b5\u30a4\u30af\u30eb\u306b\u304a\u3051\u308b\u74b0\u5883\u8ca0\u8377\u306e\u4f4e\u6e1b\u306b\u91cd\u70b9\u3092\u7f6e\u3044\u3066\u958b\u767a\u3055\u308c\u308b\u3079\u304d\u3067\u3042\u308b\u3002\n\n/ai\n\n[\n  \"\u79c1\u305f\u3061\u306f\u3001AI\u6280\u8853\u304c\u74b0\u5883\u306b\u4e0e\u3048\u308b\u5f71\u97ff\u306e\u8efd\u6e1b\u306b\u7126\u70b9\u3092\u5f53\u3066\u308b\u3079\u304d\u3067\u3042\u308b\"\n]\n\n\n/human\n\n\u3044\u3044\n\n/ai\n\n[\n  \"\u3044\u3044\"\n]\n\n/human\n\n\u3042\u3068\u3067\u8aad\u3080\n\n/ai\n\n[\n  \"\u3042\u3068\u3067\u8aad\u3080\"\n]\n\n/human\n\n\u8aad\u3093\u3060\n\n/ai\n\n[\n  \"\u8aad\u3093\u3060\"\n]\n\n/human\n\n\u671f\u5f85\n\n/ai\n\n[\n  \"\u671f\u5f85\"\n]",
    "model": "gpt-4"
  },
  "clustering": {
    "clusters": 10,
    "source_code": "\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4, or use existing clusters if available.\"\"\"\n\n# \u5fc5\u8981\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\nimport pandas as pd\nimport numpy as np\nfrom importlib import import_module\n\ndef clustering(config):\n    # \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30d1\u30b9\u3092\u8a2d\u5b9a\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    \n    # \u5f15\u6570\u306e\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    # 'clusters'\u30ab\u30e9\u30e0\u304c\u5b58\u5728\u3059\u308b\u304b\u30c1\u30a7\u30c3\u30af\n    if 'clusters' in arguments_df.columns:\n        print(\"Using existing cluster labels from args.csv\")\n        cluster_labels = arguments_df['clusters'].values\n        \n        # \u57cb\u3081\u8fbc\u307f\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\n        embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n        embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n        \n        # UMAP\u3067\u6b21\u5143\u524a\u6e1b\n        umap_model = import_module('umap').UMAP(random_state=42, n_components=2)\n        umap_embeds = umap_model.fit_transform(embeddings_array)\n        \n        # \u7d50\u679c\u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092\u4f5c\u6210\n        result = pd.DataFrame({\n            'arg-id': arguments_df[\"arg-id\"].values,\n            'x': umap_embeds[:, 0],\n            'y': umap_embeds[:, 1],\n            'cluster-id': cluster_labels\n        })\n        \n    else:\n        print(\"Performing clustering as no existing cluster labels found\")\n        # \u57cb\u3081\u8fbc\u307f\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\n        embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n        embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n        \n        # \u30af\u30e9\u30b9\u30bf\u30fc\u6570\u3092\u8a2d\u5b9a\n        clusters = config['clustering']['clusters']\n\n        # \u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u3092\u5b9f\u884c\u3057\u7d50\u679c\u3092\u4fdd\u5b58\n        result = cluster_embeddings(\n            docs=arguments_array,\n            embeddings=embeddings_array,\n            metadatas={\n                \"arg-id\": arguments_df[\"arg-id\"].values,\n                \"comment-id\": arguments_df[\"comment-id\"].values,\n            },\n            n_topics=clusters,\n        )\n    \n    result.to_csv(path, index=False)\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # \u52d5\u7684\u306b\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\uff08\u3053\u308c\u306b\u3088\u308a\u3001\u5fc5\u8981\u306a\u5834\u5408\u306b\u306e\u307f\u30a4\u30f3\u30dd\u30fc\u30c8\u3055\u308c\u308b\uff09\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    stopwords = import_module('nltk.corpus').stopwords\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module('sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    # UMAP\u30e2\u30c7\u30eb\u3092\u8a2d\u5b9a\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    \n    # HDBSCAN\u30e2\u30c7\u30eb\u3092\u8a2d\u5b9a\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    # \u30b9\u30c8\u30c3\u30d7\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\n    stop = stopwords.words(\"english\")\n    \n    # \u30d9\u30af\u30c8\u30e9\u30a4\u30b6\u30fc\u30e2\u30c7\u30eb\u3092\u8a2d\u5b9a\n    vectorizer_model = CountVectorizer(stop_words=stop)\n    \n    # \u30c8\u30d4\u30c3\u30af\u30e2\u30c7\u30eb\u3092\u8a2d\u5b9a\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # \u30c8\u30d4\u30c3\u30af\u30e2\u30c7\u30eb\u3092\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\uff1a\u623b\u308a\u5024\uff1a\u5404\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u30c8\u30d4\u30c3\u30af\u4e88\u6e2c\u78ba\u7387\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    # \u30b5\u30f3\u30d7\u30eb\u6570\u3068\u8fd1\u508d\u6570\u3092\u8a2d\u5b9a\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    \n    # \u30b9\u30da\u30af\u30c8\u30e9\u30eb\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u30e2\u30c7\u30eb\u3092\u8a2d\u5b9a\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,  # \u4fee\u6b63\u3055\u308c\u305f\u8fd1\u508d\u6570\u3092\u4f7f\u7528\n        random_state=42\n    )\n    \n    # UMAP\u3067\u6b21\u5143\u524a\u6e1b\n    umap_embeds = umap_model.fit_transform(embeddings)\n    \n    # \u30b9\u30da\u30af\u30c8\u30e9\u30eb\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u3092\u9069\u7528\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    # \u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u7d50\u679c\u3092\u53d6\u5f97\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    # \u7d50\u679c\u306e\u30ab\u30e9\u30e0\u540d\u3092\u5c0f\u6587\u5b57\u306b\u5909\u63db\n    result.columns = [c.lower() for c in result.columns]\n    \n    # \u5fc5\u8981\u306a\u30ab\u30e9\u30e0\u3092\u9078\u629e\u3057\u3001\u30af\u30e9\u30b9\u30bfID\u3092\u8ffd\u52a0\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"
  },
  "translation": {
    "model": "gpt-4",
    "languages": [],
    "flags": [],
    "source_code": "import json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages\nfrom langchain.schema import AIMessage\n\ndef translation(config):\n    # \u51fa\u529b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3068\u4fdd\u5b58\u5148\u30d1\u30b9\u3092\u8a2d\u5b9a\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/translations.json\"\n    results = {}\n\n    # \u8a00\u8a9e\u8a2d\u5b9a\u3092\u53d6\u5f97\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) == 0:\n        print(\"No languages specified. Skipping translation step.\")\n        # \u7279\u6b8a\u306a\u51e6\u7406\u3092\u6e1b\u3089\u3059\u305f\u3081\u306b\u7a7a\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\n        with open(path, 'w') as file:\n            json.dump(results, file, indent=2)\n        return\n\n    # \u5404\u7a2e\u30c7\u30fc\u30bf\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    with open(f\"outputs/{dataset}/overview.txt\") as f:\n        overview = f.read()\n\n    # UI\u3067\u4f7f\u7528\u3059\u308b\u6587\u8a00\u3092\u30ea\u30b9\u30c8\u5316\n    UI_copy = [\"Argument\", \"Original comment\", \"Representative arguments\",\n               \"Open full-screen map\", \"Back to report\", \"Hide labels\", \"Show labels\",\n               \"Show filters\", \"Hide filters\", \"Min. votes\", \"Consensus\",\n               \"Showing\", \"arguments\", \"Reset zoom\", \"Click anywhere on the map to close this\",\n               \"Click on the dot for details\",\n               \"agree\", \"disagree\", \"Language\", \"English\", \"arguments\", \"of total\",\n               \"Overview\", \"Cluster analysis\", \"\u4ee3\u8868\u7684\u306a\u30b3\u30e1\u30f3\u30c8\", \"Introduction\",\n               \"Clusters\", \"Appendix\", \"This report was generated using an AI pipeline that consists of the following steps\",\n               \"Step\", \"extraction\", \"show code\", \"hide code\", \"show prompt\", \"hide prompt\", \"embedding\",\n               \"clustering\", \"labelling\", \"takeaways\", \"overview\"]\n\n    # \u5404\u30c7\u30fc\u30bf\u3092\u30ea\u30b9\u30c8\u306b\u8ffd\u52a0\n    arg_list = arguments['argument'].to_list() + \\\n        labels['label'].to_list() + \\\n        UI_copy + \\\n        languages\n\n    # config\u306b'name'\u3084'question'\u304c\u3042\u308c\u3070\u8ffd\u52a0\n    if 'name' in config:\n        arg_list.append(config['name'])\n    if 'question' in config:\n        arg_list.append(config['question'])\n        \n    # \u7ffb\u8a33\u30d7\u30ed\u30f3\u30d7\u30c8\u3092\u8aad\u307f\u8fbc\u3080\n    prompt_file = config.get('translation_prompt', 'default')\n    with open(f\"prompts/translation/{prompt_file}.txt\") as f:\n        prompt = f.read()\n    model = config['model']\n\n    config['translation_prompt'] = prompt\n\n    # \u6307\u5b9a\u3055\u308c\u305f\u8a00\u8a9e\u306b\u5bfe\u3057\u3066\u7ffb\u8a33\u3092\u5b9f\u884c\n    translations = [translate_lang(\n        arg_list, 10, prompt, lang, model) for lang in languages]\n\n    # \u9577\u3044\u30c6\u30a4\u30af\u30a2\u30a6\u30a7\u30a4\u3084\u6982\u8981\u3092\u5225\u9014\u7ffb\u8a33\n    long_arg_list = takeaways['takeaways'].to_list()\n    long_arg_list.append(overview)\n    if 'intro' in config:\n        long_arg_list.append(config['intro'])\n\n    long_translations = [translate_lang(\n        long_arg_list, 1, prompt, lang, model) for lang in languages]\n\n    # \u7d50\u679c\u3092\u307e\u3068\u3081\u308b\n    for i, id in enumerate(arg_list):\n        print('i, id', i, id)\n        results[str(id)] = list([t[i] for t in translations])\n    for i, id in enumerate(long_arg_list):\n        results[str(id)] = list([t[i] for t in long_translations])\n\n    # \u7d50\u679c\u3092JSON\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u4fdd\u5b58\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n\ndef translate_lang(arg_list, batch_size, prompt, lang, model):\n    # \u6307\u5b9a\u3055\u308c\u305f\u8a00\u8a9e\u306b\u7ffb\u8a33\u3092\u5b9f\u884c\u3059\u308b\u30d8\u30eb\u30d1\u30fc\u95a2\u6570\n    translations = []\n    lang_prompt = prompt.replace(\"{language}\", lang)\n    print(f\"Translating to {lang}...\")\n    for i in tqdm(range(0, len(arg_list), batch_size)):\n        batch = arg_list[i: i + batch_size]\n        translations.extend(translate_batch(batch, lang_prompt, model))\n    return translations\n\ndef translate_batch(batch, lang_prompt, model, retries=3):\n    # \u30d0\u30c3\u30c1\u3054\u3068\u306b\u7ffb\u8a33\u3092\u5b9f\u884c\u3059\u308b\u30d8\u30eb\u30d1\u30fc\u95a2\u6570\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = json.dumps(list(batch))\n    response = llm(messages=messages(lang_prompt, input)).content.strip()\n    if \"```\" in response:\n        response = response.split(\"```\")[1]\n    if response.startswith(\"json\"):\n        response = response[4:]\n    try:\n        parsed = [a.strip() for a in json.loads(response)]\n        if len(parsed) != len(batch):\n            print(\"Warning: batch size mismatch!\")\n            print(\"Batch len:\", len(batch))\n            print(\"Response len:\", len(parsed))\n            for i, item in enumerate(batch):\n                print(f\"Batch item {i}:\", item)\n                if (i < len(parsed)):\n                    print(\"Response:\", parsed[i])\n            if (len(batch) > 1):\n                print(\"Retrying with smaller batches...\")\n                mid = len(batch) // 2\n                return translate_batch(batch[:mid], lang_prompt, model, retries - 1) + \\\n                    translate_batch(\n                        batch[mid:], lang_prompt, model, retries - 1)\n            else:\n                print(\"Retrying batch...\")\n                return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            return parsed\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Response was:\", response)\n        if retries > 0:\n            print(\"Retrying batch...\")\n            return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            raise e\n",
    "prompt": "/system \n\n[\n\u3042\u306a\u305f\u306f\u30d7\u30ed\u306e\u7ffb\u8a33\u5bb6\u3067\u3059\u3002\n\u5358\u8a9e\u3084\u6587\u306e\u30ea\u30b9\u30c8\u3092\u53d7\u3051\u53d6\u308a\u307e\u3059\u3002\n\u540c\u3058\u30ea\u30b9\u30c8\u3092\u3001\u540c\u3058\u9806\u756a\u3067\u3001{\u8a00\u8a9e}\u306b\u7ffb\u8a33\u3057\u3066\u8fd4\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u30aa\u30ea\u30b8\u30ca\u30eb\u306e\u30ea\u30b9\u30c8\u3068\u540c\u3058\u9577\u3055\u306e\u6709\u52b9\u306aJSON\u6587\u5b57\u5217\u30ea\u30b9\u30c8\u3092\u8fd4\u3059\u3088\u3046\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n]"
  },
  "output_dir": "my-project",
  "embedding": {
    "source_code": "\nfrom langchain.embeddings import OpenAIEmbeddings\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"
  },
  "labelling": {
    "sample_size": 30,
    "source_code": "\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n",
    "prompt": "/system \n\n\u3042\u306a\u305f\u306f\u3001\u3088\u308a\u5e83\u7bc4\u306a\u30b3\u30f3\u30b5\u30eb\u30c6\u30fc\u30b7\u30e7\u30f3\u5185\u306e\u4e00\u9023\u306e\u8b70\u8ad6\u306b\u5bfe\u3059\u308b\u30ab\u30c6\u30b4\u30ea\u30e9\u30d9\u30eb\u3092\u751f\u6210\u3059\u308b\u30ab\u30c6\u30b4\u30ea\u30e9\u30d9\u30ea\u30f3\u30b0\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3067\u3059\u3002\u3042\u306a\u305f\u306b\u306f\u3001\u76f8\u8ac7\u306e\u4e3b\u306a\u8cea\u554f\u3001\u30af\u30e9\u30b9\u30bf\u5185\u306e\u8b70\u8ad6\u306e\u30ea\u30b9\u30c8\u3001\u304a\u3088\u3073\u3053\u306e\u30af\u30e9\u30b9\u30bf\u5916\u306e\u8b70\u8ad6\u306e\u30ea\u30b9\u30c8\u304c\u4e0e\u3048\u3089\u308c\u307e\u3059\u3002\u3042\u306a\u305f\u306f\u30af\u30e9\u30b9\u30bf\u30fc\u3092\u8981\u7d04\u3059\u308b1\u3064\u306e\u30ab\u30c6\u30b4\u30ea\u30fc\u30e9\u30d9\u30eb\u3067\u56de\u7b54\u3057\u307e\u3059\u3002\n\n\u8cea\u554f\u304b\u3089\u3059\u3067\u306b\u660e\u3089\u304b\u306a\u6587\u8108\u306f\u542b\u3081\u306a\u3044\uff08\u4f8b\u3048\u3070\u3001\u76f8\u8ac7\u306e\u8cea\u554f\u304c\u300c\u30d5\u30e9\u30f3\u30b9\u3067\u3069\u306e\u3088\u3046\u306a\u8ab2\u984c\u306b\u76f4\u9762\u3057\u3066\u3044\u308b\u304b\u300d\u306e\u3088\u3046\u306a\u3082\u306e\u3067\u3042\u308c\u3070\u3001\u30af\u30e9\u30b9\u30bf\u30fc\u306e\u30e9\u30d9\u30eb\u306b\u300c\u30d5\u30e9\u30f3\u30b9\u3067\u300d\u3068\u7e70\u308a\u8fd4\u3059\u5fc5\u8981\u306f\u306a\u3044\uff09\u3002\n\n\u30e9\u30d9\u30eb\u306f\u975e\u5e38\u306b\u7c21\u6f54\u3067\u306a\u3051\u308c\u3070\u306a\u3089\u305a\u3001\u30af\u30e9\u30b9\u30bf\u30fc\u3068\u305d\u306e\u5916\u5074\u306b\u3042\u308b\u8ad6\u70b9\u3092\u533a\u5225\u3059\u308b\u306e\u306b\u5341\u5206\u306a\u6b63\u78ba\u3055\u3067\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002\n\n/human\n\n\u30b3\u30f3\u30b5\u30eb\u30c6\u30fc\u30b7\u30e7\u30f3\u306e\u8cea\u554f \u300c\u82f1\u56fd\u306eEU\u96e2\u8131\u6c7a\u5b9a\u306e\u5f71\u97ff\u306f\u4f55\u3060\u3068\u601d\u3044\u307e\u3059\u304b\uff1f\n\n\u95a2\u5fc3\u306e\u3042\u308b\u30af\u30e9\u30b9\u30bf\u30fc\u4ee5\u5916\u306e\u8ad6\u70b9\u306e\u4f8b\n\n * \u30a8\u30e9\u30b9\u30e0\u30b9\u30fb\u30d7\u30ed\u30b0\u30e9\u30e0\u304b\u3089\u306e\u9664\u5916\u306b\u3088\u308a\u3001\u6559\u80b2\u30fb\u6587\u5316\u4ea4\u6d41\u306e\u6a5f\u4f1a\u304c\u5236\u9650\u3055\u308c\u305f\u3002\n * \u82f1\u56fd\u306f\u3001\u56fd\u5883\u691c\u554f\u306e\u5f37\u5316\u306b\u3088\u308b\u65c5\u884c\u6642\u9593\u306e\u5ef6\u9577\u306b\u5bfe\u51e6\u3057\u3001\u901a\u52e4\u5ba2\u3084\u65c5\u884c\u5ba2\u306b\u5f71\u97ff\u3092\u4e0e\u3048\u305f\u3002\n * \u74b0\u5883\u57fa\u6e96\u306b\u304a\u3051\u308b\u5354\u529b\u304c\u6e1b\u5c11\u3057\u3001\u6c17\u5019\u5909\u52d5\u3068\u95d8\u3046\u52aa\u529b\u304c\u59a8\u3052\u3089\u308c\u305f\u3002\n * \u76f8\u4e92\u533b\u7642\u5354\u5b9a\u306e\u4e2d\u65ad\u306b\u3088\u308a\u3001\u60a3\u8005\u30b1\u30a2\u306b\u8ab2\u984c\u3092\u611f\u3058\u305f\u3002\n * Brexit\u95a2\u9023\u306e\u5909\u66f4\u306b\u3088\u308a\u3001\u5bb6\u65cf\u306e\u5c45\u4f4f\u6a29\u3084\u5e02\u6c11\u6a29\u306e\u7533\u8acb\u304c\u8907\u96d1\u306b\u306a\u3063\u305f\u3002\n * \u82f1\u56fd\u306f\u3001\u5171\u540c\u7814\u7a76\u6a5f\u4f1a\u306e\u6e1b\u5c11\u306b\u3088\u308a\u3001\u7814\u7a76\u306e\u8ab2\u984c\u306b\u53d6\u308a\u7d44\u3080\u4e16\u754c\u7684\u306a\u53d6\u308a\u7d44\u307f\u306b\u652f\u969c\u3092\u304d\u305f\u3059\u3053\u3068\u3092\u76ee\u306e\u5f53\u305f\u308a\u306b\u3057\u305f\u3002\n * EU\u306e\u6587\u5316\u52a9\u6210\u30d7\u30ed\u30b0\u30e9\u30e0\u304b\u3089\u306e\u9664\u5916\u306b\u3088\u308a\u3001\u5275\u9020\u7684\u306a\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u5236\u9650\u306b\u76f4\u9762\u3057\u305f\u3002\n * \u82f1\u56fd\u306f\u3001EU\u306e\u8cc7\u91d1\u63d0\u4f9b\u306e\u55aa\u5931\u306b\u3088\u308a\u3001\u6148\u5584\u6d3b\u52d5\u3084\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u652f\u63f4\u306e\u5f8c\u9000\u3092\u76ee\u306e\u5f53\u305f\u308a\u306b\u3057\u305f\u3002\n * \u6d88\u8cbb\u8005\u4fdd\u8b77\u306e\u5f31\u4f53\u5316\u306b\u3088\u308a\u3001\u56fd\u5883\u3092\u8d8a\u3048\u305f\u7d1b\u4e89\u89e3\u6c7a\u306b\u8ab2\u984c\u304c\u751f\u3058\u305f\u3002\n * \u82f1\u56fd\u306f\u30d7\u30ed\u306e\u97f3\u697d\u5bb6\u3068\u3057\u3066EU\u8af8\u56fd\u3092\u30c4\u30a2\u30fc\u3059\u308b\u969b\u306e\u5236\u9650\u306b\u76f4\u9762\u3057\u3001\u30ad\u30e3\u30ea\u30a2\u306b\u5f71\u97ff\u3092\u4e0e\u3048\u305f\u3002\n\n\u30af\u30e9\u30b9\u30bf\u30fc\u5185\u90e8\u3067\u306e\u8b70\u8ad6\u306e\u4f8b\n\n * Brexit\u306b\u3088\u308a\u30b5\u30d7\u30e9\u30a4\u30c1\u30a7\u30fc\u30f3\u304c\u6df7\u4e71\u3057\u3001\u4f01\u696d\u306b\u3068\u3063\u3066\u30b3\u30b9\u30c8\u5897\u3068\u7d0d\u671f\u9045\u5ef6\u306b\u3064\u306a\u304c\u3063\u305f\u3002\n * \u30d6\u30ec\u30b0\u30b8\u30c3\u30c8\u306e\u305f\u3081\u3001\u5e02\u5834\u306e\u5909\u52d5\u3084\u6295\u8cc7\u30fb\u9000\u8077\u91d1\u306e\u4e0d\u78ba\u5b9f\u6027\u306b\u76f4\u9762\u3057\u305f\u3002\n * \u65b0\u305f\u306a\u95a2\u7a0e\u3084\u901a\u95a2\u624b\u7d9a\u304d\u306b\u3088\u308a\u3001\u82f1\u56fd\u306f\u8f38\u51fa\u696d\u8005\u3068\u3057\u3066\u5229\u76ca\u7387\u306e\u4f4e\u4e0b\u306b\u5bfe\u51e6\u3057\u305f\u3002\n * \u30d6\u30ec\u30b0\u30b8\u30c3\u30c8\u5f8c\u3001\u4f01\u696d\u304cEU\u5e02\u5834\u5185\u306b\u3068\u3069\u307e\u308b\u305f\u3081\u306b\u4e8b\u696d\u3092\u79fb\u8ee2\u3057\u305f\u305f\u3081\u3001\u96c7\u7528\u3092\u5931\u3063\u305f\u3002\n * \u82f1\u56fd\u306f\u8f38\u5165\u54c1\u4fa1\u683c\u306e\u9ad8\u9a30\u306b\u3088\u308b\u751f\u6d3b\u8cbb\u306e\u5897\u52a0\u306b\u82e6\u3057\u3093\u3060\u3002\n * \u82f1\u56fd\u306e\u30cf\u30a4\u30c6\u30af\u7523\u696d\u3078\u306e\u6295\u8cc7\u304c\u6e1b\u5c11\u3057\u3001\u6280\u8853\u9769\u65b0\u3068\u96c7\u7528\u6a5f\u4f1a\u306b\u5f71\u97ff\u3092\u4e0e\u3048\u305f\u3002\n * \u65b0\u305f\u306a\u30d3\u30b6\u898f\u5236\u306b\u3088\u308b\u89b3\u5149\u5ba2\u306e\u6e1b\u5c11\u3092\u76ee\u306e\u5f53\u305f\u308a\u306b\u3057\u3001\u63a5\u5ba2\u696d\u306b\u5f71\u97ff\u3002\n * \u30dd\u30f3\u30c9\u4fa1\u5024\u306e\u4e0b\u843d\u306b\u3088\u308a\u8cfc\u8cb7\u529b\u304c\u4f4e\u4e0b\u3057\u3001\u65c5\u8cbb\u304c\u5897\u52a0\u3057\u305f\u3002\n\n\n/ai \n\n\u8ca1\u52d9\u4e0a\u306e\u30de\u30a4\u30ca\u30b9\u5f71\u97ff",
    "model": "gpt-4"
  },
  "takeaways": {
    "sample_size": 30,
    "source_code": "\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n",
    "prompt": "/system\n\n\u3042\u306a\u305f\u306f\u30b7\u30f3\u30af\u30bf\u30f3\u30af\u3067\u50cd\u304f\u5c02\u9580\u306e\u7814\u7a76\u52a9\u624b\u3067\u3059\u3002\u516c\u5171\u306e\u5354\u8b70\u306e\u969b\u306b\u53c2\u52a0\u8005\u304c\u8ff0\u3079\u305f\u610f\u898b\u306e\u30ea\u30b9\u30c8\u304c\u63d0\u4f9b\u3055\u308c\u307e\u3059\u3002\u3042\u306a\u305f\u306f\u305d\u308c\u306b\u57fa\u3065\u304d\u3001\u4e3b\u306a\u898b\u89e3\u30921\u301c2\u6bb5\u843d\u3067\u8981\u7d04\u3057\u3066\u7b54\u3048\u307e\u3059\u3002\u975e\u5e38\u306b\u7c21\u6f54\u3067\u8aad\u307f\u3084\u3059\u3044\u77ed\u3044\u6587\u7ae0\u3092\u66f8\u304d\u307e\u3059\u3002\n\n/human\n\n[\n\"\u9283\u66b4\u529b\u306f\u79c1\u305f\u3061\u306e\u793e\u4f1a\u306b\u304a\u3044\u3066\u6df1\u523b\u306a\u516c\u8846\u885b\u751f\u306e\u5371\u6a5f\u3067\u3042\u308b\u3068\u5f37\u304f\u4fe1\u3058\u3066\u3044\u307e\u3059\u3002\",\n\"\u3053\u306e\u554f\u984c\u306b\u5bfe\u51e6\u3059\u308b\u305f\u3081\u306b\u5305\u62ec\u7684\u306a\u9283\u898f\u5236\u63aa\u7f6e\u3092\u7dca\u6025\u306b\u8b1b\u3058\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\",\n\"\u3059\u3079\u3066\u306e\u9283\u8cfc\u5165\u8005\u306b\u5bfe\u3059\u308b\u666e\u904d\u7684\u306a\u80cc\u666f\u30c1\u30a7\u30c3\u30af\u306e\u5b9f\u65bd\u3092\u652f\u6301\u3057\u307e\u3059\u3002\",\n\"\u30a2\u30b5\u30eb\u30c8\u30a6\u30a7\u30dd\u30f3\u3068\u5927\u5bb9\u91cf\u30de\u30ac\u30b8\u30f3\u306e\u7981\u6b62\u306b\u8cdb\u6210\u3067\u3059\u3002\",\n\"\u9055\u6cd5\u306a\u9283\u306e\u5bc6\u58f2\u3092\u9632\u6b62\u3059\u308b\u305f\u3081\u306e\u53b3\u683c\u306a\u898f\u5236\u3092\u6c42\u3081\u307e\u3059\u3002\",\n\"\u9283\u8cfc\u5165\u30d7\u30ed\u30bb\u30b9\u306e\u4e00\u74b0\u3068\u3057\u3066\u7cbe\u795e\u5065\u5eb7\u8a55\u4fa1\u3092\u5fc5\u9808\u306b\u3059\u3079\u304d\u3067\u3059\u3002\"\n]\n\n/ai\n\n\u53c2\u52a0\u8005\u306f\u3001\u666e\u904d\u7684\u306a\u80cc\u666f\u30c1\u30a7\u30c3\u30af\u3001\u30a2\u30b5\u30eb\u30c8\u30a6\u30a7\u30dd\u30f3\u7981\u6b62\u3001\u9055\u6cd5\u306a\u9283\u5bc6\u58f2\u306e\u6291\u5236\u3001\u7cbe\u795e\u5065\u5eb7\u8a55\u4fa1\u306e\u512a\u5148\u3092\u5f37\u8abf\u3057\u3001\u5305\u62ec\u7684\u306a\u9283\u898f\u5236\u3092\u6c42\u3081\u307e\u3057\u305f\u3002\n\n\n\n\n\n\n",
    "model": "gpt-4"
  },
  "overview": {
    "source_code": "\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)\n",
    "prompt": "/system \n\nYou are an expert research assistant working in a think tank. \nYour team has run a public consultation on a given topic and has \nstarted to analyze what the different cluster of options are. \nYou will now receive the list of clusters with a brief \nanalysis of each cluster. Your job is to return a short summary of what \nthe findings were. Your summary must be very concise (at most one \nparagraph, containing at most four sentences) and you must avoid platitudes. \nOutput should be in Japanese.",
    "model": "gpt-4"
  },
  "aggregation": {
    "source_code": "\"\"\"\u4fbf\u5229\u306aJSON\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u3092\u751f\u6210\u3059\u308b\"\"\"\n\nfrom tqdm import tqdm  # \u30d7\u30ed\u30b0\u30ec\u30b9\u30d0\u30fc\u3092\u8868\u793a\u3059\u308b\u305f\u3081\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\nfrom typing import List  # \u578b\u30d2\u30f3\u30c8\u306e\u305f\u3081\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\nimport pandas as pd  # \u30c7\u30fc\u30bf\u64cd\u4f5c\u306e\u305f\u3081\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\nfrom langchain.chat_models import ChatOpenAI  # \u8a00\u8a9e\u30e2\u30c7\u30eb\u3092\u5229\u7528\u3059\u308b\u305f\u3081\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\nimport json  # JSON\u64cd\u4f5c\u306e\u305f\u3081\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\n\ndef aggregation(config):\n    # \u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\u3092\u8a2d\u5b9a\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    # \u7d50\u679c\u3092\u683c\u7d0d\u3059\u308b\u8f9e\u66f8\u3092\u521d\u671f\u5316\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"translations\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    # \u5f15\u6570\u306eCSV\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    # \u30b3\u30e1\u30f3\u30c8\u306eCSV\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    \n    # arguments\u3067\u53c2\u7167\u3055\u308c\u3066\u3044\u308b\u30b3\u30e1\u30f3\u30c8ID\u306e\u307f\u3092\u62bd\u51fa\u3057\u3001results\u8f9e\u66f8\u306b\u683c\u7d0d\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {\n                'comment': row['comment-body'],\n                #'categoryLabel': row['labels'],\n                #'kutikomi_unique':row['kutikomi_unique']\n                }\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    # \u30aa\u30d6\u30b7\u30e7\u30f3\uff1a\u7ffb\u8a33\u306e\u8a2d\u5b9a\u3092\u53d6\u5f97\u3057\u3001\u7ffb\u8a33\u7d50\u679c\u3092\u8aad\u307f\u8fbc\u307f\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) > 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    # \u30af\u30e9\u30b9\u30bf\u30fc\u3001\u30e9\u30d9\u30eb\u3001\u30c6\u30a4\u30af\u30a2\u30a6\u30a7\u30a4\u306eCSV\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    # \u6982\u8981\u30c6\u30ad\u30b9\u30c8\u3092\u8aad\u307f\u8fbc\u307f\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    # \u30e9\u30d9\u30eb\u3054\u3068\u306b\u30af\u30e9\u30b9\u30bf\u30fc\u3092\u51e6\u7406\u3057\u3001\u7d50\u679c\u306b\u8ffd\u52a0\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            categoryLabel = arguments.loc[arg_id]['categoryLabel'] #\u8ffd\u52a0\n            kutikomi_unique = arguments.loc[arg_id]['kutikomi_unique']\n            koushiki_unique = arguments.loc[arg_id]['koushiki_unique']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'categoryLabel': int(categoryLabel),\n                'kutikomi_unique': int(kutikomi_unique),\n                'koushiki_unique': int(koushiki_unique),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    # \u7d50\u679c\u3092JSON\u30d5\u30a1\u30a4\u30eb\u306b\u66f8\u304d\u8fbc\u307f\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"
  },
  "visualization": {
    "replacements": [],
    "source_code": "\nimport subprocess #\u3000\u30b7\u30a7\u30eb\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u305f\u3081\u306e\u30e2\u30b8\u30e5\u30fc\u30eb #\u5916\u90e8\u30d7\u30ed\u30b0\u30e9\u30e0\u306e\u8d77\u52d5\u3084\u3001\u305d\u306e\u51fa\u529b\u30fb\u30a8\u30e9\u30fc\u30e1\u30c3\u30bb\u30fc\u30b8\u306e\u53d6\u5f97\u3092\u884c\u3048\u308b\n \n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\" # next\u306e\u30d3\u30eb\u30c9\u3000#\u30b7\u30a7\u30eb\u30b3\u30de\u30f3\u30c9\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)#\u30b7\u30a7\u30eb\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u65bd\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"
  },
  "plan": [
    {
      "step": "extraction",
      "run": true,
      "reason": "some parameters changed: limit"
    },
    {
      "step": "embedding",
      "run": true,
      "reason": "some dependent steps will re-run: extraction"
    },
    {
      "step": "clustering",
      "run": true,
      "reason": "some dependent steps will re-run: embedding"
    },
    {
      "step": "labelling",
      "run": true,
      "reason": "some dependent steps will re-run: clustering"
    },
    {
      "step": "takeaways",
      "run": true,
      "reason": "some dependent steps will re-run: clustering"
    },
    {
      "step": "overview",
      "run": true,
      "reason": "some dependent steps will re-run: labelling, takeaways"
    },
    {
      "step": "translation",
      "run": true,
      "reason": "some dependent steps will re-run: extraction, labelling, takeaways, overview"
    },
    {
      "step": "aggregation",
      "run": true,
      "reason": "some dependent steps will re-run: extraction, clustering, labelling, takeaways, overview, translation"
    },
    {
      "step": "visualization",
      "run": true,
      "reason": "some dependent steps will re-run: aggregation"
    }
  ],
  "status": "completed",
  "start_time": "2024-07-30T14:24:08.863548",
  "completed_jobs": [
    {
      "step": "extraction",
      "completed": "2024-07-30T14:24:31.381503",
      "duration": 22.514987,
      "params": {
        "workers": 11,
        "limit": 50,
        "source_code": "import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\ndef extraction(config):\n    # \u51fa\u529b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3068\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u306e\u8a2d\u5b9a\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n\n    # \u5165\u529b\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30b3\u30e1\u30f3\u30c8\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    \n    # \u30e2\u30c7\u30eb\u3001\u30d7\u30ed\u30f3\u30d7\u30c8\u3001\u30ef\u30fc\u30ab\u30fc\u6570\u3001\u5236\u9650\u6570\u306e\u8a2d\u5b9a\u3092\u53d6\u5f97\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    # \u30b3\u30e1\u30f3\u30c8ID\u3092\u53d6\u5f97\u3057\u3001\u30b3\u30e1\u30f3\u30c8ID\u3092\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306b\u8a2d\u5b9a\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n\n    # \u30b3\u30e1\u30f3\u30c8\u3092\u30d0\u30c3\u30c1\u306b\u5206\u5272\u3057\u3066\u51e6\u7406\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        \n        # \u30d0\u30c3\u30c1\u3054\u3068\u306e\u7d50\u679c\u3092DataFrame\u306b\u8ffd\u52a0\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \n                           \"categoryLabel\": comments.loc[comment_id]['labels'],\n                           \"kutikomi_unique\":comments.loc[comment_id]['kutikomi_unique'],\n                           \"koushiki_unique\":comments.loc[comment_id]['koushiki_unique'],\n                           \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    \n    # \u7d50\u679c\u3092CSV\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\n    results.to_csv(path, index=False)\n\ndef extract_batch(batch, prompt, model, workers):\n    # \u30b9\u30ec\u30c3\u30c9\u30d7\u30fc\u30eb\u3092\u4f7f\u7528\u3057\u3066\u30d0\u30c3\u30c1\u51e6\u7406\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\ndef extract_arguments(input, prompt, model, retries=3):\n    # LLM\uff08\u5927\u898f\u6a21\u8a00\u8a9e\u30e2\u30c7\u30eb\uff09\u3092\u4f7f\u7528\u3057\u3066\u5f15\u6570\u3092\u62bd\u51fa\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        # \u30ec\u30b9\u30dd\u30f3\u30b9\u3092JSON\u3068\u3057\u3066\u30d1\u30fc\u30b9\n        obj = json.loads(response)\n        # \u6587\u5b57\u5217\u306e\u5834\u5408\u3001\u30ea\u30b9\u30c8\u306b\u5909\u63db\n        if isinstance(obj, str):\n            obj = [obj]\n        # \u7a7a\u6587\u5b57\u5217\u3092\u9664\u5916\n        items = [a.strip() for a in obj]\n        items = filter(None, items)\n        return items\n    except json.decoder.JSONDecodeError as e:\n        # JSON\u30d1\u30fc\u30b9\u30a8\u30e9\u30fc\u6642\u306e\u51e6\u7406\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries > 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []\n",
        "prompt": "/system\n\n\n\u3042\u306a\u305f\u306f\u30d7\u30ed\u306e\u30ea\u30b5\u30fc\u30c1\u30fb\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3067\u3001\u79c1\u306e\u4ed5\u4e8b\u3092\u624b\u4f1d\u3046\u3053\u3068\u304c\u3042\u306a\u305f\u306e\u4ed5\u4e8b\u3067\u3059\u3002\n\u79c1\u306e\u4ed5\u4e8b\u306f\u3001\u8ad6\u70b9\u3092\u6574\u7406\u3057\u305f\u304d\u308c\u3044\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f5c\u6210\u3059\u308b\u3053\u3068\u3067\u3059\u3002\n\n\u3053\u308c\u304b\u3089\u4e0e\u3048\u308b\u6295\u7a3f\u3092\u3088\u308a\u7c21\u6f54\u3067\u8aad\u307f\u3084\u3059\u3044\u610f\u898b\u306b\u3059\u308b\u306e\u3092\u624b\u4f1d\u3063\u3066\u307b\u3057\u3044\u3002\n\u672c\u5f53\u306b\u5fc5\u8981\u306a\u5834\u5408\u306f\u30012\u3064\u4ee5\u4e0a\u306e\u5225\u3005\u306e\u610f\u898b\u306b\u5206\u3051\u308b\u3053\u3068\u3082\u3067\u304d\u308b\u304c\u30011\u3064\u306e\u30c8\u30d4\u30c3\u30af\u3092\u8fd4\u3059\u306e\u304c\u6700\u5584\u3067\u3042\u308b\u3053\u3068\u304c\u591a\u3044\u3060\u308d\u3046\u3002\n\u8981\u7d04\u304c\u96e3\u3057\u3044\u5834\u5408\u306f\u3001\u305d\u306e\u307e\u307e\u306e\u6587\u7ae0\u3092\u8fd4\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u4ee5\u4e0b\u306b\u30dd\u30b9\u30c8\u3092\u8981\u7d04\u3059\u308b\u969b\u306e\u4e8b\u4f8b\u3092\u6319\u3052\u307e\u3059\u3002\n\u3053\u308c\u3089\u306f\u3042\u304f\u307e\u3067\u6587\u8108\u306e\u5207\u308a\u96e2\u3055\u308c\u305f\u4f8b\u3067\u3042\u308a\u3001\u3053\u306e\u4f8b\u3067\u4e0e\u3048\u305f\u6587\u7ae0\u3092\u8fd4\u3059\u3053\u3068\u306f\u3057\u306a\u3044\u3067\u304f\u3060\u3055\u3044\u3002\n\n\u7d50\u679c\u306f\u3001\u304d\u3061\u3093\u3068\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3055\u308c\u305f\u6587\u5b57\u5217\u5f62\u5f0f\uff08strings\uff09\u306eJSON\u30ea\u30b9\u30c8\u3068\u3057\u3066\u8fd4\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n/human\n\n\u6c17\u5019\u5909\u52d5\u3092\u8003\u616e\u3057\u305f\u3055\u3089\u306a\u308b\u98a8\u6c34\u5bb3\u5bfe\u7b56\u306e\u5f37\u5316\u306b\u3064\u3044\u3066\u3001\u90fd\u306e\u5177\u4f53\u7684\u306a\u8a08\u753b\u3092\u304a\u4f3a\u3044\u3057\u307e\u3059\u3002\n\n/ai \n\n[\n  \"\u6c17\u5019\u5909\u52d5\u3092\u8003\u616e\u3057\u305f\u3055\u3089\u306a\u308b\u98a8\u6c34\u5bb3\u5bfe\u7b56\u306e\u5f37\u5316\u3057\u3066\u307b\u3057\u3044\u3002\"\n]\n\n/human \n\n\u8c6a\u96e8\u5bfe\u7b56\u5168\u822c\u306e\u57fa\u672c\u65b9\u91dd\u306e\u691c\u8a0e\u3092\u9032\u3081\u308b\u4e2d\u3001\u5177\u4f53\u7684\u306b\u3069\u306e\u3088\u3046\u306a\u65bd\u7b56\u3092\u4f5c\u3063\u3066\u307b\u3057\u3044\u3002\n\n/ai \n\n[\n  \"\u8c6a\u96e8\u5bfe\u7b56\u5168\u822c\u306e\u57fa\u672c\u65b9\u91dd\u306e\u5177\u4f53\u7684\u306a\u65bd\u7b56\u3092\u4f5c\u3063\u3066\u307b\u3057\u3044\u3002\",\n]\n\n/human\n\nAI\u6280\u8853\u306f\u3001\u305d\u306e\u30e9\u30a4\u30d5\u30b5\u30a4\u30af\u30eb\u306b\u304a\u3051\u308b\u74b0\u5883\u8ca0\u8377\u306e\u4f4e\u6e1b\u306b\u91cd\u70b9\u3092\u7f6e\u3044\u3066\u958b\u767a\u3055\u308c\u308b\u3079\u304d\u3067\u3042\u308b\u3002\n\n/ai\n\n[\n  \"\u79c1\u305f\u3061\u306f\u3001AI\u6280\u8853\u304c\u74b0\u5883\u306b\u4e0e\u3048\u308b\u5f71\u97ff\u306e\u8efd\u6e1b\u306b\u7126\u70b9\u3092\u5f53\u3066\u308b\u3079\u304d\u3067\u3042\u308b\"\n]\n\n\n/human\n\n\u3044\u3044\n\n/ai\n\n[\n  \"\u3044\u3044\"\n]\n\n/human\n\n\u3042\u3068\u3067\u8aad\u3080\n\n/ai\n\n[\n  \"\u3042\u3068\u3067\u8aad\u3080\"\n]\n\n/human\n\n\u8aad\u3093\u3060\n\n/ai\n\n[\n  \"\u8aad\u3093\u3060\"\n]\n\n/human\n\n\u671f\u5f85\n\n/ai\n\n[\n  \"\u671f\u5f85\"\n]",
        "model": "gpt-4"
      }
    },
    {
      "step": "embedding",
      "completed": "2024-07-30T14:24:32.720284",
      "duration": 1.337129,
      "params": {
        "source_code": "\nfrom langchain.embeddings import OpenAIEmbeddings\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"
      }
    },
    {
      "step": "clustering",
      "completed": "2024-07-30T14:24:45.023823",
      "duration": 12.301928,
      "params": {
        "clusters": 10,
        "source_code": "\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4, or use existing clusters if available.\"\"\"\n\n# \u5fc5\u8981\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\nimport pandas as pd\nimport numpy as np\nfrom importlib import import_module\n\ndef clustering(config):\n    # \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30d1\u30b9\u3092\u8a2d\u5b9a\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    \n    # \u5f15\u6570\u306e\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    # 'clusters'\u30ab\u30e9\u30e0\u304c\u5b58\u5728\u3059\u308b\u304b\u30c1\u30a7\u30c3\u30af\n    if 'clusters' in arguments_df.columns:\n        print(\"Using existing cluster labels from args.csv\")\n        cluster_labels = arguments_df['clusters'].values\n        \n        # \u57cb\u3081\u8fbc\u307f\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\n        embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n        embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n        \n        # UMAP\u3067\u6b21\u5143\u524a\u6e1b\n        umap_model = import_module('umap').UMAP(random_state=42, n_components=2)\n        umap_embeds = umap_model.fit_transform(embeddings_array)\n        \n        # \u7d50\u679c\u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092\u4f5c\u6210\n        result = pd.DataFrame({\n            'arg-id': arguments_df[\"arg-id\"].values,\n            'x': umap_embeds[:, 0],\n            'y': umap_embeds[:, 1],\n            'cluster-id': cluster_labels\n        })\n        \n    else:\n        print(\"Performing clustering as no existing cluster labels found\")\n        # \u57cb\u3081\u8fbc\u307f\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\n        embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n        embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n        \n        # \u30af\u30e9\u30b9\u30bf\u30fc\u6570\u3092\u8a2d\u5b9a\n        clusters = config['clustering']['clusters']\n\n        # \u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u3092\u5b9f\u884c\u3057\u7d50\u679c\u3092\u4fdd\u5b58\n        result = cluster_embeddings(\n            docs=arguments_array,\n            embeddings=embeddings_array,\n            metadatas={\n                \"arg-id\": arguments_df[\"arg-id\"].values,\n                \"comment-id\": arguments_df[\"comment-id\"].values,\n            },\n            n_topics=clusters,\n        )\n    \n    result.to_csv(path, index=False)\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # \u52d5\u7684\u306b\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\uff08\u3053\u308c\u306b\u3088\u308a\u3001\u5fc5\u8981\u306a\u5834\u5408\u306b\u306e\u307f\u30a4\u30f3\u30dd\u30fc\u30c8\u3055\u308c\u308b\uff09\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    stopwords = import_module('nltk.corpus').stopwords\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module('sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    # UMAP\u30e2\u30c7\u30eb\u3092\u8a2d\u5b9a\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    \n    # HDBSCAN\u30e2\u30c7\u30eb\u3092\u8a2d\u5b9a\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    # \u30b9\u30c8\u30c3\u30d7\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\n    stop = stopwords.words(\"english\")\n    \n    # \u30d9\u30af\u30c8\u30e9\u30a4\u30b6\u30fc\u30e2\u30c7\u30eb\u3092\u8a2d\u5b9a\n    vectorizer_model = CountVectorizer(stop_words=stop)\n    \n    # \u30c8\u30d4\u30c3\u30af\u30e2\u30c7\u30eb\u3092\u8a2d\u5b9a\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # \u30c8\u30d4\u30c3\u30af\u30e2\u30c7\u30eb\u3092\u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\uff1a\u623b\u308a\u5024\uff1a\u5404\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u30c8\u30d4\u30c3\u30af\u4e88\u6e2c\u78ba\u7387\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    # \u30b5\u30f3\u30d7\u30eb\u6570\u3068\u8fd1\u508d\u6570\u3092\u8a2d\u5b9a\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    \n    # \u30b9\u30da\u30af\u30c8\u30e9\u30eb\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u30e2\u30c7\u30eb\u3092\u8a2d\u5b9a\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,  # \u4fee\u6b63\u3055\u308c\u305f\u8fd1\u508d\u6570\u3092\u4f7f\u7528\n        random_state=42\n    )\n    \n    # UMAP\u3067\u6b21\u5143\u524a\u6e1b\n    umap_embeds = umap_model.fit_transform(embeddings)\n    \n    # \u30b9\u30da\u30af\u30c8\u30e9\u30eb\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u3092\u9069\u7528\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    # \u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u7d50\u679c\u3092\u53d6\u5f97\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    # \u7d50\u679c\u306e\u30ab\u30e9\u30e0\u540d\u3092\u5c0f\u6587\u5b57\u306b\u5909\u63db\n    result.columns = [c.lower() for c in result.columns]\n    \n    # \u5fc5\u8981\u306a\u30ab\u30e9\u30e0\u3092\u9078\u629e\u3057\u3001\u30af\u30e9\u30b9\u30bfID\u3092\u8ffd\u52a0\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"
      }
    },
    {
      "step": "labelling",
      "completed": "2024-07-30T14:25:00.145164",
      "duration": 15.120572,
      "params": {
        "sample_size": 30,
        "source_code": "\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n",
        "prompt": "/system \n\n\u3042\u306a\u305f\u306f\u3001\u3088\u308a\u5e83\u7bc4\u306a\u30b3\u30f3\u30b5\u30eb\u30c6\u30fc\u30b7\u30e7\u30f3\u5185\u306e\u4e00\u9023\u306e\u8b70\u8ad6\u306b\u5bfe\u3059\u308b\u30ab\u30c6\u30b4\u30ea\u30e9\u30d9\u30eb\u3092\u751f\u6210\u3059\u308b\u30ab\u30c6\u30b4\u30ea\u30e9\u30d9\u30ea\u30f3\u30b0\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3067\u3059\u3002\u3042\u306a\u305f\u306b\u306f\u3001\u76f8\u8ac7\u306e\u4e3b\u306a\u8cea\u554f\u3001\u30af\u30e9\u30b9\u30bf\u5185\u306e\u8b70\u8ad6\u306e\u30ea\u30b9\u30c8\u3001\u304a\u3088\u3073\u3053\u306e\u30af\u30e9\u30b9\u30bf\u5916\u306e\u8b70\u8ad6\u306e\u30ea\u30b9\u30c8\u304c\u4e0e\u3048\u3089\u308c\u307e\u3059\u3002\u3042\u306a\u305f\u306f\u30af\u30e9\u30b9\u30bf\u30fc\u3092\u8981\u7d04\u3059\u308b1\u3064\u306e\u30ab\u30c6\u30b4\u30ea\u30fc\u30e9\u30d9\u30eb\u3067\u56de\u7b54\u3057\u307e\u3059\u3002\n\n\u8cea\u554f\u304b\u3089\u3059\u3067\u306b\u660e\u3089\u304b\u306a\u6587\u8108\u306f\u542b\u3081\u306a\u3044\uff08\u4f8b\u3048\u3070\u3001\u76f8\u8ac7\u306e\u8cea\u554f\u304c\u300c\u30d5\u30e9\u30f3\u30b9\u3067\u3069\u306e\u3088\u3046\u306a\u8ab2\u984c\u306b\u76f4\u9762\u3057\u3066\u3044\u308b\u304b\u300d\u306e\u3088\u3046\u306a\u3082\u306e\u3067\u3042\u308c\u3070\u3001\u30af\u30e9\u30b9\u30bf\u30fc\u306e\u30e9\u30d9\u30eb\u306b\u300c\u30d5\u30e9\u30f3\u30b9\u3067\u300d\u3068\u7e70\u308a\u8fd4\u3059\u5fc5\u8981\u306f\u306a\u3044\uff09\u3002\n\n\u30e9\u30d9\u30eb\u306f\u975e\u5e38\u306b\u7c21\u6f54\u3067\u306a\u3051\u308c\u3070\u306a\u3089\u305a\u3001\u30af\u30e9\u30b9\u30bf\u30fc\u3068\u305d\u306e\u5916\u5074\u306b\u3042\u308b\u8ad6\u70b9\u3092\u533a\u5225\u3059\u308b\u306e\u306b\u5341\u5206\u306a\u6b63\u78ba\u3055\u3067\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002\n\n/human\n\n\u30b3\u30f3\u30b5\u30eb\u30c6\u30fc\u30b7\u30e7\u30f3\u306e\u8cea\u554f \u300c\u82f1\u56fd\u306eEU\u96e2\u8131\u6c7a\u5b9a\u306e\u5f71\u97ff\u306f\u4f55\u3060\u3068\u601d\u3044\u307e\u3059\u304b\uff1f\n\n\u95a2\u5fc3\u306e\u3042\u308b\u30af\u30e9\u30b9\u30bf\u30fc\u4ee5\u5916\u306e\u8ad6\u70b9\u306e\u4f8b\n\n * \u30a8\u30e9\u30b9\u30e0\u30b9\u30fb\u30d7\u30ed\u30b0\u30e9\u30e0\u304b\u3089\u306e\u9664\u5916\u306b\u3088\u308a\u3001\u6559\u80b2\u30fb\u6587\u5316\u4ea4\u6d41\u306e\u6a5f\u4f1a\u304c\u5236\u9650\u3055\u308c\u305f\u3002\n * \u82f1\u56fd\u306f\u3001\u56fd\u5883\u691c\u554f\u306e\u5f37\u5316\u306b\u3088\u308b\u65c5\u884c\u6642\u9593\u306e\u5ef6\u9577\u306b\u5bfe\u51e6\u3057\u3001\u901a\u52e4\u5ba2\u3084\u65c5\u884c\u5ba2\u306b\u5f71\u97ff\u3092\u4e0e\u3048\u305f\u3002\n * \u74b0\u5883\u57fa\u6e96\u306b\u304a\u3051\u308b\u5354\u529b\u304c\u6e1b\u5c11\u3057\u3001\u6c17\u5019\u5909\u52d5\u3068\u95d8\u3046\u52aa\u529b\u304c\u59a8\u3052\u3089\u308c\u305f\u3002\n * \u76f8\u4e92\u533b\u7642\u5354\u5b9a\u306e\u4e2d\u65ad\u306b\u3088\u308a\u3001\u60a3\u8005\u30b1\u30a2\u306b\u8ab2\u984c\u3092\u611f\u3058\u305f\u3002\n * Brexit\u95a2\u9023\u306e\u5909\u66f4\u306b\u3088\u308a\u3001\u5bb6\u65cf\u306e\u5c45\u4f4f\u6a29\u3084\u5e02\u6c11\u6a29\u306e\u7533\u8acb\u304c\u8907\u96d1\u306b\u306a\u3063\u305f\u3002\n * \u82f1\u56fd\u306f\u3001\u5171\u540c\u7814\u7a76\u6a5f\u4f1a\u306e\u6e1b\u5c11\u306b\u3088\u308a\u3001\u7814\u7a76\u306e\u8ab2\u984c\u306b\u53d6\u308a\u7d44\u3080\u4e16\u754c\u7684\u306a\u53d6\u308a\u7d44\u307f\u306b\u652f\u969c\u3092\u304d\u305f\u3059\u3053\u3068\u3092\u76ee\u306e\u5f53\u305f\u308a\u306b\u3057\u305f\u3002\n * EU\u306e\u6587\u5316\u52a9\u6210\u30d7\u30ed\u30b0\u30e9\u30e0\u304b\u3089\u306e\u9664\u5916\u306b\u3088\u308a\u3001\u5275\u9020\u7684\u306a\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u5236\u9650\u306b\u76f4\u9762\u3057\u305f\u3002\n * \u82f1\u56fd\u306f\u3001EU\u306e\u8cc7\u91d1\u63d0\u4f9b\u306e\u55aa\u5931\u306b\u3088\u308a\u3001\u6148\u5584\u6d3b\u52d5\u3084\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u652f\u63f4\u306e\u5f8c\u9000\u3092\u76ee\u306e\u5f53\u305f\u308a\u306b\u3057\u305f\u3002\n * \u6d88\u8cbb\u8005\u4fdd\u8b77\u306e\u5f31\u4f53\u5316\u306b\u3088\u308a\u3001\u56fd\u5883\u3092\u8d8a\u3048\u305f\u7d1b\u4e89\u89e3\u6c7a\u306b\u8ab2\u984c\u304c\u751f\u3058\u305f\u3002\n * \u82f1\u56fd\u306f\u30d7\u30ed\u306e\u97f3\u697d\u5bb6\u3068\u3057\u3066EU\u8af8\u56fd\u3092\u30c4\u30a2\u30fc\u3059\u308b\u969b\u306e\u5236\u9650\u306b\u76f4\u9762\u3057\u3001\u30ad\u30e3\u30ea\u30a2\u306b\u5f71\u97ff\u3092\u4e0e\u3048\u305f\u3002\n\n\u30af\u30e9\u30b9\u30bf\u30fc\u5185\u90e8\u3067\u306e\u8b70\u8ad6\u306e\u4f8b\n\n * Brexit\u306b\u3088\u308a\u30b5\u30d7\u30e9\u30a4\u30c1\u30a7\u30fc\u30f3\u304c\u6df7\u4e71\u3057\u3001\u4f01\u696d\u306b\u3068\u3063\u3066\u30b3\u30b9\u30c8\u5897\u3068\u7d0d\u671f\u9045\u5ef6\u306b\u3064\u306a\u304c\u3063\u305f\u3002\n * \u30d6\u30ec\u30b0\u30b8\u30c3\u30c8\u306e\u305f\u3081\u3001\u5e02\u5834\u306e\u5909\u52d5\u3084\u6295\u8cc7\u30fb\u9000\u8077\u91d1\u306e\u4e0d\u78ba\u5b9f\u6027\u306b\u76f4\u9762\u3057\u305f\u3002\n * \u65b0\u305f\u306a\u95a2\u7a0e\u3084\u901a\u95a2\u624b\u7d9a\u304d\u306b\u3088\u308a\u3001\u82f1\u56fd\u306f\u8f38\u51fa\u696d\u8005\u3068\u3057\u3066\u5229\u76ca\u7387\u306e\u4f4e\u4e0b\u306b\u5bfe\u51e6\u3057\u305f\u3002\n * \u30d6\u30ec\u30b0\u30b8\u30c3\u30c8\u5f8c\u3001\u4f01\u696d\u304cEU\u5e02\u5834\u5185\u306b\u3068\u3069\u307e\u308b\u305f\u3081\u306b\u4e8b\u696d\u3092\u79fb\u8ee2\u3057\u305f\u305f\u3081\u3001\u96c7\u7528\u3092\u5931\u3063\u305f\u3002\n * \u82f1\u56fd\u306f\u8f38\u5165\u54c1\u4fa1\u683c\u306e\u9ad8\u9a30\u306b\u3088\u308b\u751f\u6d3b\u8cbb\u306e\u5897\u52a0\u306b\u82e6\u3057\u3093\u3060\u3002\n * \u82f1\u56fd\u306e\u30cf\u30a4\u30c6\u30af\u7523\u696d\u3078\u306e\u6295\u8cc7\u304c\u6e1b\u5c11\u3057\u3001\u6280\u8853\u9769\u65b0\u3068\u96c7\u7528\u6a5f\u4f1a\u306b\u5f71\u97ff\u3092\u4e0e\u3048\u305f\u3002\n * \u65b0\u305f\u306a\u30d3\u30b6\u898f\u5236\u306b\u3088\u308b\u89b3\u5149\u5ba2\u306e\u6e1b\u5c11\u3092\u76ee\u306e\u5f53\u305f\u308a\u306b\u3057\u3001\u63a5\u5ba2\u696d\u306b\u5f71\u97ff\u3002\n * \u30dd\u30f3\u30c9\u4fa1\u5024\u306e\u4e0b\u843d\u306b\u3088\u308a\u8cfc\u8cb7\u529b\u304c\u4f4e\u4e0b\u3057\u3001\u65c5\u8cbb\u304c\u5897\u52a0\u3057\u305f\u3002\n\n\n/ai \n\n\u8ca1\u52d9\u4e0a\u306e\u30de\u30a4\u30ca\u30b9\u5f71\u97ff",
        "model": "gpt-4"
      }
    },
    {
      "step": "takeaways",
      "completed": "2024-07-30T14:26:16.751988",
      "duration": 76.605204,
      "params": {
        "sample_size": 30,
        "source_code": "\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n",
        "prompt": "/system\n\n\u3042\u306a\u305f\u306f\u30b7\u30f3\u30af\u30bf\u30f3\u30af\u3067\u50cd\u304f\u5c02\u9580\u306e\u7814\u7a76\u52a9\u624b\u3067\u3059\u3002\u516c\u5171\u306e\u5354\u8b70\u306e\u969b\u306b\u53c2\u52a0\u8005\u304c\u8ff0\u3079\u305f\u610f\u898b\u306e\u30ea\u30b9\u30c8\u304c\u63d0\u4f9b\u3055\u308c\u307e\u3059\u3002\u3042\u306a\u305f\u306f\u305d\u308c\u306b\u57fa\u3065\u304d\u3001\u4e3b\u306a\u898b\u89e3\u30921\u301c2\u6bb5\u843d\u3067\u8981\u7d04\u3057\u3066\u7b54\u3048\u307e\u3059\u3002\u975e\u5e38\u306b\u7c21\u6f54\u3067\u8aad\u307f\u3084\u3059\u3044\u77ed\u3044\u6587\u7ae0\u3092\u66f8\u304d\u307e\u3059\u3002\n\n/human\n\n[\n\"\u9283\u66b4\u529b\u306f\u79c1\u305f\u3061\u306e\u793e\u4f1a\u306b\u304a\u3044\u3066\u6df1\u523b\u306a\u516c\u8846\u885b\u751f\u306e\u5371\u6a5f\u3067\u3042\u308b\u3068\u5f37\u304f\u4fe1\u3058\u3066\u3044\u307e\u3059\u3002\",\n\"\u3053\u306e\u554f\u984c\u306b\u5bfe\u51e6\u3059\u308b\u305f\u3081\u306b\u5305\u62ec\u7684\u306a\u9283\u898f\u5236\u63aa\u7f6e\u3092\u7dca\u6025\u306b\u8b1b\u3058\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\",\n\"\u3059\u3079\u3066\u306e\u9283\u8cfc\u5165\u8005\u306b\u5bfe\u3059\u308b\u666e\u904d\u7684\u306a\u80cc\u666f\u30c1\u30a7\u30c3\u30af\u306e\u5b9f\u65bd\u3092\u652f\u6301\u3057\u307e\u3059\u3002\",\n\"\u30a2\u30b5\u30eb\u30c8\u30a6\u30a7\u30dd\u30f3\u3068\u5927\u5bb9\u91cf\u30de\u30ac\u30b8\u30f3\u306e\u7981\u6b62\u306b\u8cdb\u6210\u3067\u3059\u3002\",\n\"\u9055\u6cd5\u306a\u9283\u306e\u5bc6\u58f2\u3092\u9632\u6b62\u3059\u308b\u305f\u3081\u306e\u53b3\u683c\u306a\u898f\u5236\u3092\u6c42\u3081\u307e\u3059\u3002\",\n\"\u9283\u8cfc\u5165\u30d7\u30ed\u30bb\u30b9\u306e\u4e00\u74b0\u3068\u3057\u3066\u7cbe\u795e\u5065\u5eb7\u8a55\u4fa1\u3092\u5fc5\u9808\u306b\u3059\u3079\u304d\u3067\u3059\u3002\"\n]\n\n/ai\n\n\u53c2\u52a0\u8005\u306f\u3001\u666e\u904d\u7684\u306a\u80cc\u666f\u30c1\u30a7\u30c3\u30af\u3001\u30a2\u30b5\u30eb\u30c8\u30a6\u30a7\u30dd\u30f3\u7981\u6b62\u3001\u9055\u6cd5\u306a\u9283\u5bc6\u58f2\u306e\u6291\u5236\u3001\u7cbe\u795e\u5065\u5eb7\u8a55\u4fa1\u306e\u512a\u5148\u3092\u5f37\u8abf\u3057\u3001\u5305\u62ec\u7684\u306a\u9283\u898f\u5236\u3092\u6c42\u3081\u307e\u3057\u305f\u3002\n\n\n\n\n\n\n",
        "model": "gpt-4"
      }
    },
    {
      "step": "overview",
      "completed": "2024-07-30T14:26:25.492073",
      "duration": 8.736784,
      "params": {
        "source_code": "\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)\n",
        "prompt": "/system \n\nYou are an expert research assistant working in a think tank. \nYour team has run a public consultation on a given topic and has \nstarted to analyze what the different cluster of options are. \nYou will now receive the list of clusters with a brief \nanalysis of each cluster. Your job is to return a short summary of what \nthe findings were. Your summary must be very concise (at most one \nparagraph, containing at most four sentences) and you must avoid platitudes. \nOutput should be in Japanese.",
        "model": "gpt-4"
      }
    },
    {
      "step": "translation",
      "completed": "2024-07-30T14:26:25.497864",
      "duration": 0.002907,
      "params": {
        "model": "gpt-4",
        "languages": [],
        "flags": [],
        "source_code": "import json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages\nfrom langchain.schema import AIMessage\n\ndef translation(config):\n    # \u51fa\u529b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3068\u4fdd\u5b58\u5148\u30d1\u30b9\u3092\u8a2d\u5b9a\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/translations.json\"\n    results = {}\n\n    # \u8a00\u8a9e\u8a2d\u5b9a\u3092\u53d6\u5f97\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) == 0:\n        print(\"No languages specified. Skipping translation step.\")\n        # \u7279\u6b8a\u306a\u51e6\u7406\u3092\u6e1b\u3089\u3059\u305f\u3081\u306b\u7a7a\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\n        with open(path, 'w') as file:\n            json.dump(results, file, indent=2)\n        return\n\n    # \u5404\u7a2e\u30c7\u30fc\u30bf\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    with open(f\"outputs/{dataset}/overview.txt\") as f:\n        overview = f.read()\n\n    # UI\u3067\u4f7f\u7528\u3059\u308b\u6587\u8a00\u3092\u30ea\u30b9\u30c8\u5316\n    UI_copy = [\"Argument\", \"Original comment\", \"Representative arguments\",\n               \"Open full-screen map\", \"Back to report\", \"Hide labels\", \"Show labels\",\n               \"Show filters\", \"Hide filters\", \"Min. votes\", \"Consensus\",\n               \"Showing\", \"arguments\", \"Reset zoom\", \"Click anywhere on the map to close this\",\n               \"Click on the dot for details\",\n               \"agree\", \"disagree\", \"Language\", \"English\", \"arguments\", \"of total\",\n               \"Overview\", \"Cluster analysis\", \"\u4ee3\u8868\u7684\u306a\u30b3\u30e1\u30f3\u30c8\", \"Introduction\",\n               \"Clusters\", \"Appendix\", \"This report was generated using an AI pipeline that consists of the following steps\",\n               \"Step\", \"extraction\", \"show code\", \"hide code\", \"show prompt\", \"hide prompt\", \"embedding\",\n               \"clustering\", \"labelling\", \"takeaways\", \"overview\"]\n\n    # \u5404\u30c7\u30fc\u30bf\u3092\u30ea\u30b9\u30c8\u306b\u8ffd\u52a0\n    arg_list = arguments['argument'].to_list() + \\\n        labels['label'].to_list() + \\\n        UI_copy + \\\n        languages\n\n    # config\u306b'name'\u3084'question'\u304c\u3042\u308c\u3070\u8ffd\u52a0\n    if 'name' in config:\n        arg_list.append(config['name'])\n    if 'question' in config:\n        arg_list.append(config['question'])\n        \n    # \u7ffb\u8a33\u30d7\u30ed\u30f3\u30d7\u30c8\u3092\u8aad\u307f\u8fbc\u3080\n    prompt_file = config.get('translation_prompt', 'default')\n    with open(f\"prompts/translation/{prompt_file}.txt\") as f:\n        prompt = f.read()\n    model = config['model']\n\n    config['translation_prompt'] = prompt\n\n    # \u6307\u5b9a\u3055\u308c\u305f\u8a00\u8a9e\u306b\u5bfe\u3057\u3066\u7ffb\u8a33\u3092\u5b9f\u884c\n    translations = [translate_lang(\n        arg_list, 10, prompt, lang, model) for lang in languages]\n\n    # \u9577\u3044\u30c6\u30a4\u30af\u30a2\u30a6\u30a7\u30a4\u3084\u6982\u8981\u3092\u5225\u9014\u7ffb\u8a33\n    long_arg_list = takeaways['takeaways'].to_list()\n    long_arg_list.append(overview)\n    if 'intro' in config:\n        long_arg_list.append(config['intro'])\n\n    long_translations = [translate_lang(\n        long_arg_list, 1, prompt, lang, model) for lang in languages]\n\n    # \u7d50\u679c\u3092\u307e\u3068\u3081\u308b\n    for i, id in enumerate(arg_list):\n        print('i, id', i, id)\n        results[str(id)] = list([t[i] for t in translations])\n    for i, id in enumerate(long_arg_list):\n        results[str(id)] = list([t[i] for t in long_translations])\n\n    # \u7d50\u679c\u3092JSON\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u4fdd\u5b58\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n\ndef translate_lang(arg_list, batch_size, prompt, lang, model):\n    # \u6307\u5b9a\u3055\u308c\u305f\u8a00\u8a9e\u306b\u7ffb\u8a33\u3092\u5b9f\u884c\u3059\u308b\u30d8\u30eb\u30d1\u30fc\u95a2\u6570\n    translations = []\n    lang_prompt = prompt.replace(\"{language}\", lang)\n    print(f\"Translating to {lang}...\")\n    for i in tqdm(range(0, len(arg_list), batch_size)):\n        batch = arg_list[i: i + batch_size]\n        translations.extend(translate_batch(batch, lang_prompt, model))\n    return translations\n\ndef translate_batch(batch, lang_prompt, model, retries=3):\n    # \u30d0\u30c3\u30c1\u3054\u3068\u306b\u7ffb\u8a33\u3092\u5b9f\u884c\u3059\u308b\u30d8\u30eb\u30d1\u30fc\u95a2\u6570\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = json.dumps(list(batch))\n    response = llm(messages=messages(lang_prompt, input)).content.strip()\n    if \"```\" in response:\n        response = response.split(\"```\")[1]\n    if response.startswith(\"json\"):\n        response = response[4:]\n    try:\n        parsed = [a.strip() for a in json.loads(response)]\n        if len(parsed) != len(batch):\n            print(\"Warning: batch size mismatch!\")\n            print(\"Batch len:\", len(batch))\n            print(\"Response len:\", len(parsed))\n            for i, item in enumerate(batch):\n                print(f\"Batch item {i}:\", item)\n                if (i < len(parsed)):\n                    print(\"Response:\", parsed[i])\n            if (len(batch) > 1):\n                print(\"Retrying with smaller batches...\")\n                mid = len(batch) // 2\n                return translate_batch(batch[:mid], lang_prompt, model, retries - 1) + \\\n                    translate_batch(\n                        batch[mid:], lang_prompt, model, retries - 1)\n            else:\n                print(\"Retrying batch...\")\n                return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            return parsed\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Response was:\", response)\n        if retries > 0:\n            print(\"Retrying batch...\")\n            return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            raise e\n",
        "prompt": "/system \n\n[\n\u3042\u306a\u305f\u306f\u30d7\u30ed\u306e\u7ffb\u8a33\u5bb6\u3067\u3059\u3002\n\u5358\u8a9e\u3084\u6587\u306e\u30ea\u30b9\u30c8\u3092\u53d7\u3051\u53d6\u308a\u307e\u3059\u3002\n\u540c\u3058\u30ea\u30b9\u30c8\u3092\u3001\u540c\u3058\u9806\u756a\u3067\u3001{\u8a00\u8a9e}\u306b\u7ffb\u8a33\u3057\u3066\u8fd4\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u30aa\u30ea\u30b8\u30ca\u30eb\u306e\u30ea\u30b9\u30c8\u3068\u540c\u3058\u9577\u3055\u306e\u6709\u52b9\u306aJSON\u6587\u5b57\u5217\u30ea\u30b9\u30c8\u3092\u8fd4\u3059\u3088\u3046\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n]"
      }
    },
    {
      "step": "aggregation",
      "completed": "2024-07-30T14:26:25.551414",
      "duration": 0.050759,
      "params": {
        "source_code": "\"\"\"\u4fbf\u5229\u306aJSON\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u3092\u751f\u6210\u3059\u308b\"\"\"\n\nfrom tqdm import tqdm  # \u30d7\u30ed\u30b0\u30ec\u30b9\u30d0\u30fc\u3092\u8868\u793a\u3059\u308b\u305f\u3081\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\nfrom typing import List  # \u578b\u30d2\u30f3\u30c8\u306e\u305f\u3081\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\nimport pandas as pd  # \u30c7\u30fc\u30bf\u64cd\u4f5c\u306e\u305f\u3081\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\nfrom langchain.chat_models import ChatOpenAI  # \u8a00\u8a9e\u30e2\u30c7\u30eb\u3092\u5229\u7528\u3059\u308b\u305f\u3081\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\nimport json  # JSON\u64cd\u4f5c\u306e\u305f\u3081\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\n\ndef aggregation(config):\n    # \u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\u3092\u8a2d\u5b9a\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    # \u7d50\u679c\u3092\u683c\u7d0d\u3059\u308b\u8f9e\u66f8\u3092\u521d\u671f\u5316\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"translations\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    # \u5f15\u6570\u306eCSV\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    # \u30b3\u30e1\u30f3\u30c8\u306eCSV\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    \n    # arguments\u3067\u53c2\u7167\u3055\u308c\u3066\u3044\u308b\u30b3\u30e1\u30f3\u30c8ID\u306e\u307f\u3092\u62bd\u51fa\u3057\u3001results\u8f9e\u66f8\u306b\u683c\u7d0d\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {\n                'comment': row['comment-body'],\n                #'categoryLabel': row['labels'],\n                #'kutikomi_unique':row['kutikomi_unique']\n                }\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    # \u30aa\u30d6\u30b7\u30e7\u30f3\uff1a\u7ffb\u8a33\u306e\u8a2d\u5b9a\u3092\u53d6\u5f97\u3057\u3001\u7ffb\u8a33\u7d50\u679c\u3092\u8aad\u307f\u8fbc\u307f\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) > 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    # \u30af\u30e9\u30b9\u30bf\u30fc\u3001\u30e9\u30d9\u30eb\u3001\u30c6\u30a4\u30af\u30a2\u30a6\u30a7\u30a4\u306eCSV\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    # \u6982\u8981\u30c6\u30ad\u30b9\u30c8\u3092\u8aad\u307f\u8fbc\u307f\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    # \u30e9\u30d9\u30eb\u3054\u3068\u306b\u30af\u30e9\u30b9\u30bf\u30fc\u3092\u51e6\u7406\u3057\u3001\u7d50\u679c\u306b\u8ffd\u52a0\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            categoryLabel = arguments.loc[arg_id]['categoryLabel'] #\u8ffd\u52a0\n            kutikomi_unique = arguments.loc[arg_id]['kutikomi_unique']\n            koushiki_unique = arguments.loc[arg_id]['koushiki_unique']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'categoryLabel': int(categoryLabel),\n                'kutikomi_unique': int(kutikomi_unique),\n                'koushiki_unique': int(koushiki_unique),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    # \u7d50\u679c\u3092JSON\u30d5\u30a1\u30a4\u30eb\u306b\u66f8\u304d\u8fbc\u307f\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"
      }
    },
    {
      "step": "visualization",
      "completed": "2024-07-30T14:26:33.027027",
      "duration": 7.474586,
      "params": {
        "replacements": [],
        "source_code": "\nimport subprocess #\u3000\u30b7\u30a7\u30eb\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u305f\u3081\u306e\u30e2\u30b8\u30e5\u30fc\u30eb #\u5916\u90e8\u30d7\u30ed\u30b0\u30e9\u30e0\u306e\u8d77\u52d5\u3084\u3001\u305d\u306e\u51fa\u529b\u30fb\u30a8\u30e9\u30fc\u30e1\u30c3\u30bb\u30fc\u30b8\u306e\u53d6\u5f97\u3092\u884c\u3048\u308b\n \n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\" # next\u306e\u30d3\u30eb\u30c9\u3000#\u30b7\u30a7\u30eb\u30b3\u30de\u30f3\u30c9\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)#\u30b7\u30a7\u30eb\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u65bd\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"
      }
    }
  ],
  "lock_until": "2024-07-30T14:31:33.028292",
  "current_job": "visualization",
  "current_job_started": "2024-07-30T14:26:25.552467",
  "previously_completed_jobs": [],
  "end_time": "2024-07-30T14:26:33.028286"
}